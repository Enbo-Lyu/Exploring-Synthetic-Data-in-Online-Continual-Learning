{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7bed34-8b0f-4a14-9682-ecfa8624ec13",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!python3 --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3881a47",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.set_device(1)\n",
    "if torch.cuda.is_available():\n",
    "    current_gpu = torch.cuda.current_device()\n",
    "    print(f\"Current default GPU index: {current_gpu}\")\n",
    "    print(f\"Current default GPU name: {torch.cuda.get_device_name(current_gpu)}\")\n",
    "else:\n",
    "    print(\"No GPUs available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535be0ec-7017-4b24-8bba-1bc38c66b939",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from diffusers import AutoPipelineForText2Image, AutoPipelineForImage2Image\n",
    "from diffusers.utils import load_image\n",
    "\n",
    "import torch\n",
    "\n",
    "pipe = AutoPipelineForImage2Image.from_pretrained(\"stabilityai/sdxl-turbo\", torch_dtype=torch.float16, variant=\"fp16\")\n",
    "pipe.to(\"cuda\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6fe7de9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "def display_images_side_by_side(image_paths, captions):\n",
    "    # Number of images\n",
    "    n = len(image_paths)\n",
    "    \n",
    "    # Set up the figure with subplots\n",
    "    fig, axes = plt.subplots(1, n, figsize=(4, 2))  # Adjust figure size as needed\n",
    "    \n",
    "    # Loop through images, their axes, and captions\n",
    "    for ax, img_path, caption in zip(axes, image_paths, captions):\n",
    "        # Load and display the image\n",
    "        img = mpimg.imread(img_path)\n",
    "        ax.imshow(img)\n",
    "        ax.axis('off')  # Turn off axis\n",
    "        \n",
    "        # Set the caption\n",
    "        ax.set_title(caption, fontsize=10, pad=10)  # Adjust font size and padding as needed\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aece21fe",
   "metadata": {},
   "source": [
    "## image generation with sdxl_turbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4cc4ae3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# dataset\n",
    "import torchvision\n",
    "\n",
    "from avalanche.benchmarks import SplitMNIST, SplitCIFAR100\n",
    "from avalanche.benchmarks.classic import SplitCIFAR100\n",
    "from avalanche.benchmarks.classic import SplitCIFAR10\n",
    "from avalanche.benchmarks.utils.data_loader import GroupBalancedDataLoader, ReplayDataLoader\n",
    "from avalanche.benchmarks.generators import nc_benchmark, ni_benchmark\n",
    "from avalanche.benchmarks.generators import filelist_benchmark, dataset_benchmark, \\\n",
    "                                            tensors_benchmark, paths_benchmark\n",
    "\n",
    "from avalanche.logging import InteractiveLogger, TensorboardLogger, \\\n",
    "    WandBLogger, TextLogger, TensorboardLogger\n",
    "\n",
    "from avalanche.training.plugins import EvaluationPlugin\n",
    "from avalanche.evaluation.metrics import forgetting_metrics, accuracy_metrics, loss_metrics\n",
    "\n",
    "from avalanche.training.plugins.checkpoint import CheckpointPlugin, \\\n",
    "    FileSystemCheckpointStorage\n",
    "from avalanche.training.determinism.rng_manager import RNGManager\n",
    "from avalanche.training import Naive, CWRStar, Replay, GDumb, \\\n",
    "    Cumulative, LwF, GEM, AGEM, EWC, AR1\n",
    "from avalanche.models import SimpleMLP\n",
    "from avalanche.training import Naive, CWRStar, Replay, GDumb, \\\n",
    "    Cumulative, LwF, GEM, AGEM, EWC, AR1\n",
    "from avalanche.models import SimpleMLP\n",
    "from avalanche.training.plugins import ReplayPlugin\n",
    "from types import SimpleNamespace\n",
    "from avalanche.training.storage_policy import ParametricBuffer, RandomExemplarsSelectionStrategy\n",
    "\n",
    "# all imports\n",
    "\n",
    "import torch\n",
    "import os\n",
    "from torch import cat, Tensor\n",
    "from torch.nn import Module\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import Subset, ConcatDataset, TensorDataset\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import SGD\n",
    "from torchvision import datasets, transforms\n",
    "import torch.optim.lr_scheduler # ?\n",
    "from torchvision.transforms import Compose, ToTensor, Normalize, RandomCrop, CenterCrop, RandomHorizontalFlip, Resize\n",
    "from torchvision.transforms.functional import center_crop\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "from torchvision.utils import save_image\n",
    "from torchvision.transforms.functional import pil_to_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1dcdbe5-b6ee-4fc3-9419-38d6cf4ea8b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sdxl_main import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b973f0d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe5e59e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def count_txt_files(directory):\n",
    "    \"\"\"\n",
    "    Counts the number of .txt files in the specified directory.\n",
    "\n",
    "    Args:\n",
    "    directory (str): The path to the directory to search for .txt files.\n",
    "\n",
    "    Returns:\n",
    "    int: The number of .txt files in the directory.\n",
    "    \"\"\"\n",
    "    txt_count = 0\n",
    "    # List all files and directories in the specified directory\n",
    "    for entry in os.listdir(directory):\n",
    "        # Construct full path\n",
    "        full_path = os.path.join(directory, entry)\n",
    "        # Check if it's a file with a .txt extension\n",
    "        if os.path.isfile(full_path) and entry.endswith('.txt'):\n",
    "            txt_count += 1\n",
    "    \n",
    "    return txt_count\n",
    "\n",
    "def count_png_files(folder_path):\n",
    "    # Ensure the folder exists\n",
    "    if not os.path.exists(folder_path):\n",
    "        print(\"The specified folder does not exist.\")\n",
    "        return 0\n",
    "    \n",
    "    # List all files in the directory\n",
    "    files = os.listdir(folder_path)\n",
    "    \n",
    "    # Filter and count files that end with .txt\n",
    "    txt_files_count = sum(1 for file in files if file.endswith('.png'))\n",
    "    \n",
    "    return txt_files_count\n",
    "\n",
    "def count_jpeg_files(folder_path):\n",
    "    # Ensure the folder exists\n",
    "    if not os.path.exists(folder_path):\n",
    "        print(\"The specified folder does not exist.\")\n",
    "        return 0\n",
    "    \n",
    "    # List all files in the directory\n",
    "    files = os.listdir(folder_path)\n",
    "    \n",
    "    # Filter and count files that end with .txt\n",
    "    txt_files_count = sum(1 for file in files if file.endswith('.JPEG'))\n",
    "    \n",
    "    return txt_files_count\n",
    "\n",
    "# count_png_files('/storage3/enbo/saved_data/imageget_sdxl_llava_i2i_synfromreal_s8g2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b059e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "benchmark = SplitCIFAR100(n_experiences=20,\n",
    "                          seed = 41,             \n",
    "                          )\n",
    "\n",
    "orders = benchmark.classes_order\n",
    "order_list = [orders[x:x+5] for x in range(0, len(orders), 5)]\n",
    "print(order_list)\n",
    "\n",
    "# order_sample = [order[3:] for order in order_list]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1541ec6c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "def load_json(file_path):\n",
    "    \"\"\"\n",
    "    Load a JSON file and return the data.\n",
    "\n",
    "    :param file_path: Path to the JSON file.\n",
    "    :return: Parsed JSON data.\n",
    "    \"\"\"\n",
    "    with open(file_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    return data\n",
    "\n",
    "def process_labels(json_data):\n",
    "    \"\"\"\n",
    "    Process the labels from the JSON data.\n",
    "\n",
    "    :param json_data: The JSON data containing labels and class names.\n",
    "    \"\"\"\n",
    "    for identifier, class_name in json_data.items():\n",
    "        print(f\"ID: {identifier}, Class Name: {class_name}\")\n",
    "\n",
    "def replace_spaces_with_underscores(class_names):\n",
    "    modified_names = []\n",
    "    for name in class_names:\n",
    "        # Replace spaces with underscores\n",
    "        modified_name = name.replace(' ', '_')\n",
    "        modified_names.append(modified_name)\n",
    "    return modified_names\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ef6250",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "from avalanche.benchmarks import SplitMNIST, SplitCIFAR100\n",
    "\n",
    "stats = ((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "\n",
    "transform = transform_train = Compose([\n",
    "    # Resize(224),\n",
    "    # Resize(384),\n",
    "    # RandomHorizontalFlip(),\n",
    "    ToTensor(),\n",
    "    # Normalize(*stats,inplace=True)\n",
    "])\n",
    "\n",
    "# Load the CIFAR-100 training set\n",
    "trainset = torchvision.datasets.CIFAR100(root='data', train=True,download=True, transform=transform)\n",
    "\n",
    "name_list = trainset.classes\n",
    "integer_to_name = {i: name_list[i] for i in range(100)}\n",
    "import json\n",
    "\n",
    "def read_json(json_path):\n",
    "# Step 1: Open the JSON file\n",
    "    with open(json_path, 'r') as file:\n",
    "    # Step 2: Load the JSON data\n",
    "        data = json.load(file)\n",
    "    return data\n",
    "\n",
    "\n",
    "name_to_integer = {name_list[i]: i for i in range(100)}\n",
    "\n",
    "# sythnthesis classes\n",
    "benchmark = SplitCIFAR100(n_experiences=20,\n",
    "                          seed = 41,             \n",
    "                          )\n",
    "\n",
    "orders = benchmark.classes_order\n",
    "order_list = [orders[x:x+5] for x in range(0, len(orders), 5)]\n",
    "\n",
    "syn_class_list = [order[3:] for order in order_list]\n",
    "syn_classes = [item for lists in syn_class_list for item in lists]\n",
    "\n",
    "real_classes = list(set([i for i in range(100)]) - set(syn_classes))\n",
    "print(len(real_classes))\n",
    "\n",
    "\n",
    "\n",
    "# order_sample = [order[3:] for order in order_list]\n",
    "classname_list = []\n",
    "label_list = []\n",
    "classname_list_sep = []\n",
    "for order_l in syn_class_list:\n",
    "    label_list.append(order_l)\n",
    "    cur_classname = [integer_to_name[i] for i in order_l]\n",
    "    classname_list.append(cur_classname)\n",
    "classname_list_sep = [item for lists in classname_list for item in lists]\n",
    "label_list_sep = [item for lists in label_list for item in lists]\n",
    "print(label_list_sep)\n",
    "\n",
    "# label_list_sep = [order[3] for order in order_list]\n",
    "# print(label_list_sep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca41d9e9-a267-484c-9bc4-c10ee1a9d0b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "real_to_syn_id = read_json('/storage3/enbo/saved_data/cifar100_dict_40synfrom60real_id.json')\n",
    "real_to_syn_name = read_json('/storage3/enbo/saved_data/cifar100_dict_40synfrom60real_name.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74878e66-0cb8-411d-a949-4c2db1181cf5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "real_to_syn_id = {int(key): int(item) for key, item in real_to_syn_id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79226b94",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "specific_integer_to_name = {key: integer_to_name[key] for key in label_list_sep if key in integer_to_name}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6114085",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(specific_integer_to_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681f7d2d-09cf-441f-abec-9875586abb9a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "real_list = list(set([i for i in range(100)]) - set(label_list_sep))\n",
    "real_integer_to_name = {key: integer_to_name[key] for key in real_list if key in integer_to_name}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b00a9c-7d24-4478-8d99-1a6ac42b81bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(real_integer_to_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b4a1b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a74b048-2e01-4e8b-82d9-0dddb5352c59",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def split_words(word):\n",
    "    # Check if the word contains an underscore\n",
    "    if '_' in word:\n",
    "        # Split the compound word into individual words\n",
    "        words = word.split('_')\n",
    "        # Include the original compound word in the list\n",
    "        words.append(word)\n",
    "    else:\n",
    "        # If it's a single word, just return it as a list\n",
    "        words = [word]\n",
    "    return words\n",
    "\n",
    "\n",
    "def replace_words(text, word, new_word):\n",
    "    # Extract words to replace from the input word\n",
    "    words_to_replace = split_words(word)\n",
    "    \n",
    "    # Create a regular expression pattern to match the words\n",
    "    pattern = re.compile(r'\\b(?:' + '|'.join(re.escape(word) for word in words_to_replace) + r')\\b', re.IGNORECASE)\n",
    "    \n",
    "    # Replace the matched words with the new word\n",
    "    new_text = pattern.sub(new_word, text)\n",
    "    \n",
    "    return new_text\n",
    "\n",
    "# Example usage\n",
    "text = \"The image features a chambered nautilus, a spiral-shaped shell, with a silver centerpiece. The nautilus is prominently displayed, occupying a significant portion of the image. The overall mood of the image is serene and captivating, as the nautilus's unique shape and the contrasting colors of the shell and\"\n",
    "new_word = \"new_word\"\n",
    "word = \"chambered_nautilus\"\n",
    "# Replace the words\n",
    "result_text = replace_words(text, word, new_word)\n",
    "print(result_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583efbe4-4630-48ab-9b79-f62602648060",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "        indices1 = [random.randint(0, len(current_prompt_list)-1) for _ in range(num_image_replay)]\n",
    "        current_prompt_list = [current_prompt_list[item] for item in indices1]\n",
    "\n",
    "        random.seed(41)\n",
    "        indices2 = [random.randint(0, len(startimage_file_paths)-1) for _ in range(num_image_replay)]\n",
    "        current_init_image_list = [startimage_file_paths[item] for item in indices2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ac9995-ef5a-45e9-aa91-79d98ad3d812",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !rm -rf '/storage3/enbo/saved_data/imageget_sdxl_llava_i2i_synfromreal_s8g2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d2df5a-2226-48d9-91e8-ec258f8d96ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "                \n",
    "def sdxl_img2img_matching_image_prompt_real2syn(pipe,\n",
    "                                                class_dict, \n",
    "                                                image_size, \n",
    "                                                prompt_file_dict, \n",
    "                                                startimage_file_path, \n",
    "                                                integer_to_name, \n",
    "                                                dict_syn_to_real_id,\n",
    "                                                generator_seed, \n",
    "                                                num_image_replay=50,\n",
    "                                                folder_name=\"/content/sd_images\"):\n",
    "    \n",
    "    \"\"\"\n",
    "    this is specified to matching pair of lavva prompt and images\n",
    "    \"\"\"\n",
    "\n",
    "    if not os.path.exists(folder_name):\n",
    "        os.makedirs(folder_name)\n",
    "\n",
    "    for id, class_name in class_dict.items():\n",
    "        # id, class_name are synthetic id and classname\n",
    "        print(\"Generating images for class \" + str(id) + \": \" + class_name)\n",
    "\n",
    "        class_file_path = os.path.join(folder_name, f\"class{id}.txt\")\n",
    "        existing_images_count = 0\n",
    "        \n",
    "        num_images_to_generate = num_image_replay\n",
    "        \n",
    "        real_id = dict_syn_to_real_id[id] # this is the real class id that bert thinks is most similar to the current syn class\n",
    "        real_class_name = integer_to_name[real_id]\n",
    "        prompt_file_path = os.path.join(prompt_file_dict, f\"class{real_id}.txt\")\n",
    "        current_path_list, current_prompt_list = extract_prompts_fromtxts_real2syn(prompt_file_path)\n",
    "\n",
    "        # Generate the new images\n",
    "        with open(class_file_path, \"w\") as file:\n",
    "            for j, prompt in enumerate(current_prompt_list):\n",
    "                # print(prompt)\n",
    "                # syn_prompt = prompt.replace(real_class_name, class_name)\n",
    "                syn_prompt = replace_words(prompt, real_class_name, class_name)\n",
    "                print(syn_prompt)\n",
    "                # syn_image_name = class_name + f\"{j}.png\"\n",
    "                \n",
    "                real_image_name = os.path.basename(current_path_list[j])\n",
    "                syn_image_name = real_image_name.replace(real_class_name, class_name)\n",
    "\n",
    "                starting_image_path = current_path_list[j]\n",
    "                init_image = load_image(starting_image_path).resize((512, 512))\n",
    "\n",
    "                # generated image is synthetic name\n",
    "                generated_image_path = os.path.join(folder_name, syn_image_name)\n",
    "                # int(num_inference_steps * strength)\n",
    "                new_image = pipe(prompt=syn_prompt,image = init_image, \n",
    "                                strength = 0.8, \n",
    "                                num_inference_steps=25, \n",
    "                                generator = generator_seed, guidance_scale=2).images[0]\n",
    "                resized_image = new_image.resize(image_size)\n",
    "\n",
    "                resized_image.save(generated_image_path)\n",
    "\n",
    "                file.write(f\"{generated_image_path} {id}\\n\")\n",
    "\n",
    "                print(f\"Generated image {syn_image_name} for class {class_name}\")\n",
    "                \n",
    "def sdxl_img2img_matching_image_prompt(class_dict, image_size, prompt_file_dict, startimage_file_path,\n",
    "                                                          generator_seed, num_image_replay=50, folder_name=\"/content/sd_images\"):\n",
    "    \n",
    "    \"\"\"\n",
    "    this is specified to matching pair of lavva prompt and images\n",
    "    \"\"\"\n",
    "    # Create the folder if it doesn't exist\n",
    "    random.seed(42)\n",
    "    if not os.path.exists(folder_name):\n",
    "        os.makedirs(folder_name)\n",
    "    classes_to_process = list(class_dict.items())\n",
    "    classes_processed = []\n",
    "\n",
    "    while classes_to_process:\n",
    "        id, class_name = classes_to_process.pop(0)\n",
    "        print(\"Generating images for class \" + str(id) + \": \" + class_name)\n",
    "\n",
    "        class_file_path = os.path.join(folder_name, f\"class{id}.txt\")\n",
    "\n",
    "        prompt_file_path = os.path.join(prompt_file_dict, f\"class{id}.txt\")\n",
    "        current_path_list, current_prompt_list = extract_prompts_fromtxts_real2syn(prompt_file_path)\n",
    "        \n",
    "        if len(current_prompt_list) < num_image_replay:\n",
    "            print(f\"Not enough prompts for class {id}. Skipping and will revisit later.\")\n",
    "            classes_to_process.append((id, class_name))\n",
    "            continue\n",
    "\n",
    "        # Generate the new images\n",
    "        with open(class_file_path, \"w\") as file:\n",
    "            for j, prompt in enumerate(current_prompt_list):\n",
    "                # print(prompt)\n",
    "                \n",
    "                starting_image_path = current_path_list[j]\n",
    "                image_name = os.path.basename(starting_image_path)\n",
    "\n",
    "                init_image = load_image(starting_image_path).resize((512, 512))\n",
    "\n",
    "            \n",
    "                image_path = os.path.join(folder_name, image_name)\n",
    "                new_image = pipe(prompt=prompt,image = init_image, \n",
    "                                strength = 0.8, \n",
    "                                num_inference_steps=20, \n",
    "                                generator = generator_seed, guidance_scale=2).images[0]\n",
    "                resized_image = new_image.resize(image_size)\n",
    "\n",
    "                resized_image.save(image_path)\n",
    "\n",
    "                file.write(f\"{image_path} {id}\\n\")\n",
    "\n",
    "                print(f\"Generated image {image_name} for class {class_name}\")\n",
    "        classes_processed.append((id, class_name))\n",
    "        \n",
    "        # Check if all classes are processed and the while loop should be terminated\n",
    "        if len(classes_processed) == len(class_dict):\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463df020",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sdxl_img2img_moreimage_lessprompt_real2syn(pipe,\n",
    "                                                class_dict, \n",
    "                                                image_size, \n",
    "                                                prompt_file_dict, \n",
    "                                                startimage_file_path, \n",
    "                                                integer_to_name, \n",
    "                                                dict_syn_to_real_id,\n",
    "                                                generator_seed, \n",
    "                                                num_image_replay=50,\n",
    "                                                folder_name=\"/content/sd_images\"):\n",
    "    \n",
    "    \"\"\"\n",
    "    this is specified to matching pair of lavva prompt and images\n",
    "    \"\"\"\n",
    "\n",
    "    if not os.path.exists(folder_name):\n",
    "        os.makedirs(folder_name)\n",
    "\n",
    "    for id, class_name in class_dict.items():\n",
    "        # id, class_name are synthetic id and classname\n",
    "        print(\"Generating images for class \" + str(id) + \": \" + class_name)\n",
    "\n",
    "        class_file_path = os.path.join(folder_name, f\"class{id}.txt\")\n",
    "        existing_images_count = 0\n",
    "        \n",
    "        num_images_to_generate = num_image_replay\n",
    "        \n",
    "        real_id = dict_syn_to_real_id[id] # this is the real class id that bert thinks is most similar to the current syn class\n",
    "        real_class_name = integer_to_name[real_id]\n",
    "        prompt_file_path = os.path.join(prompt_file_dict, f\"class{real_id}.txt\")\n",
    "        current_path_list, current_prompt_list = extract_prompts_fromtxts_real2syn(prompt_file_path)\n",
    "        \n",
    "        current_prompt_list = current_prompt_list[:int(num_images_to_generate*0.4)]\n",
    "        print('num of prompts: ', len(current_prompt_list))\n",
    "        random.seed(42)\n",
    "        indices1 = [random.randint(0, len(current_prompt_list)-1) for _ in range(num_image_replay)]\n",
    "        current_prompt_list = [current_prompt_list[item] for item in indices1]\n",
    "        print('num of prompts: ', len(current_prompt_list))\n",
    "        \n",
    "\n",
    "        # Generate the new images\n",
    "        with open(class_file_path, \"w\") as file:\n",
    "            for j, prompt in enumerate(current_prompt_list):\n",
    "                # print(prompt)\n",
    "                # syn_prompt = prompt.replace(real_class_name, class_name)\n",
    "                syn_prompt = replace_words(prompt, real_class_name, class_name)\n",
    "                print(syn_prompt)\n",
    "                # syn_image_name = class_name + f\"{j}.png\"\n",
    "                \n",
    "                real_image_name = os.path.basename(current_path_list[j])\n",
    "                syn_image_name = real_image_name.replace(real_class_name, class_name)\n",
    "\n",
    "                starting_image_path = current_path_list[j]\n",
    "                init_image = load_image(starting_image_path).resize((512, 512))\n",
    "\n",
    "                # generated image is synthetic name\n",
    "                generated_image_path = os.path.join(folder_name, syn_image_name)\n",
    "                # int(num_inference_steps * strength)\n",
    "                new_image = pipe(prompt=syn_prompt,image = init_image, \n",
    "                                strength = 0.8, \n",
    "                                num_inference_steps=25, \n",
    "                                generator = generator_seed, guidance_scale=2).images[0]\n",
    "                resized_image = new_image.resize(image_size)\n",
    "\n",
    "                resized_image.save(generated_image_path)\n",
    "\n",
    "                file.write(f\"{generated_image_path} {id}\\n\")\n",
    "\n",
    "                print(f\"Generated image {syn_image_name} for class {class_name}\")\n",
    "                                    \n",
    "                    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b798d45a",
   "metadata": {},
   "source": [
    "# more image less prompt 40 synthetic generation, each 500 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1726fe77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(specific_integer_to_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b98d22a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "generator1 = torch.Generator(device=\"cuda\").manual_seed(42)\n",
    "# create_sdxl_data_fixed_prompts_randommultiple(integer_to_name, image_size = (32,32), prompt_file_dict = 'saved_data/llava_saved_data_310/llava_prompt_50/', generator_seed = generator1, num_image_replay=50, folder_name='saved_data/sd_turbo_500images_llava_firstthreeclasses/')\n",
    "\n",
    "sdxl_img2img_moreimage_lessprompt_real2syn(pipe, \n",
    "                                            specific_integer_to_name, image_size = (32,32),\n",
    "                                            prompt_file_dict = 'saved_data/llava_cifar100_real60_500/',\n",
    "                                startimage_file_path = 'saved_data/cifar_train_all_fortest',\n",
    "                                integer_to_name = integer_to_name,\n",
    "                                dict_syn_to_real_id = real_to_syn_id,\n",
    "                                generator_seed = generator1, num_image_replay=500, \n",
    "                                folder_name='/storage3/enbo/saved_data/cifar100_sdxl_llava_i2i_40synfrom60real_i2i_step20_40percentpromptallimg_500') # starting image and prompt from the similar class within the same experience\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a812f41f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5c5ac8-d5fe-46a0-8c77-d626f4a7762b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "generator1 = torch.Generator(device=\"cuda\").manual_seed(42)\n",
    "# create_sdxl_data_fixed_prompts_randommultiple(integer_to_name, image_size = (32,32), prompt_file_dict = 'saved_data/llava_saved_data_310/llava_prompt_50/', generator_seed = generator1, num_image_replay=50, folder_name='saved_data/sd_turbo_500images_llava_firstthreeclasses/')\n",
    "\n",
    "sdxl_img2img_matching_image_prompt_real2syn(pipe, \n",
    "                                            specific_integer_to_name, image_size = (32,32),\n",
    "                                            prompt_file_dict = 'saved_data/llava_cifar100_real60_500/',\n",
    "                                startimage_file_path = 'saved_data/cifar_train_all_fortest',\n",
    "                                integer_to_name = integer_to_name,\n",
    "                                dict_syn_to_real_id = real_to_syn_id,\n",
    "                                generator_seed = generator1, num_image_replay=500, \n",
    "                                folder_name='/storage3/enbo/saved_data/cifar100_sdxl_llava_i2i_40synfrom60real_i2i_step20') # starting image and prompt from the similar class within the same experience\n",
    "\n",
    "# sdxl_img2img_matching_image_prompt(specific_integer_to_name, \n",
    "#                                    image_size = (32,32), \n",
    "#                                    prompt_file_dict = '/storage3/enbo/saved_data/llava_cifar/cifar100_long_syn20', \n",
    "#                                    startimage_file_path = 'saved_data/cifar_train_all_fortest',\n",
    "#                                     generator_seed = generator1, \n",
    "#                                    num_image_replay=500, \n",
    "#                                 folder_name='/storage3/enbo/saved_data/cifar100_sdxl_llava_i2i_20moresyntheticreal') # starting image and prompt from the similar class within the same experience\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e3c8a2-5950-43f4-a7c3-8dd27093818a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# generate real 60 class from real image and prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c6a575-daa0-4a82-bd72-943040d51f56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "generator1 = torch.Generator(device=\"cuda\").manual_seed(42)\n",
    "create_sdxl_data_img2img_matching_image_prompt(real_integer_to_name, image_size = (224,224),\n",
    "                                               prompt_file_dict = '/scratch/local/ssd/enbo/saved_data/llava_imagenet/imagenet_long_60real',\n",
    "                                               startimage_file_path = '/scratch/local/ssd/enbo/saved_data/imagenet_train_data_allimages',\n",
    "                                               generator_seed = generator1, num_image_replay=1300, \n",
    "                                               folder_name='/storage3/enbo/saved_data/imageget_sdxl_llava_i2i_allimageprompt_s8g2')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc58c00e-455b-4db4-9d7b-1860da5ea2e0",
   "metadata": {},
   "source": [
    "## syn-real from all real images, 10% long prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7302a19-2111-4221-af0d-6b34d83b2815",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# generator1 = torch.Generator(device=\"cuda\").manual_seed(42)\n",
    "# create_sdxl_data_moreimages_lessprompts_img2img(real_integer_to_name, image_size = (32,32),\n",
    "#                                                prompt_file_dict = '/storage3/enbo/saved_data/realimages_10persent_longprompts/',\n",
    "#                                                startimage_file_path = 'saved_data/cifar_train_all_fortest/',\n",
    "#                                                generator_seed = generator1, num_image_replay=500, \n",
    "#                                                folder_name='/storage3/enbo/saved_data/sdxl_llava_i2i_allimage10percentprompt_60real')\n",
    "\n",
    "generator1 = torch.Generator(device=\"cuda\").manual_seed(42)\n",
    "# imagenet 224\n",
    "create_sdxl_data_moreimages_lessprompts_img2img(real_integer_to_name, image_size = (224,224),\n",
    "                                               prompt_file_dict = '/scratch/local/ssd/enbo/saved_data/llava_imagenet/imagenet_long_60real_10percent',\n",
    "                                               startimage_file_path = '/scratch/local/ssd/enbo/saved_data/imagenet_train_data_allimages',\n",
    "                                               generator_seed = generator1, num_image_replay=1300, \n",
    "                                               folder_name='/storage3/enbo/saved_data/imageget_sdxl_llava_i2i_allimage10percentprompt_60real')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8681f7e-339f-4e7c-8f9a-74ad2b7e6fe4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7586fd27-a5f8-4053-baa9-7c8465fc7add",
   "metadata": {},
   "source": [
    "## syn-real from 10% real images, prompts long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672132ad-38a8-4a29-91a8-3fbf3768791a",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator1 = torch.Generator(device=\"cuda\").manual_seed(42)\n",
    "\n",
    "create_sdxl_data_fixed_prompts_randommultiple_img2img_update(real_integer_to_name, image_size = (32,32),\n",
    "                                               prompt_file_dict = '/storage3/enbo/saved_data/realimages_10persent_longprompts/',\n",
    "                                               startimage_file_path = 'saved_data/llava_saved_data_310/cifar_50/',\n",
    "                                               generator_seed = generator1, num_image_replay=500, \n",
    "                                               folder_name='/storage3/enbo/saved_data/sdxl_llava_i2i_10percentimageprompt_60real')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c55090-af00-4b23-a0d6-7d724d54f2bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04894aa5-b9bb-427a-846c-c57500ed1c5c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "generator1 = torch.Generator(device=\"cuda\").manual_seed(42)\n",
    "\n",
    "create_sdxl_data_fixed_prompts_randommultiple_img2img(specific_integer_to_name, image_size = (32,32),\n",
    "                                               prompt_file_dict = 'saved_data/llava_saved_data_310/llava_prompt_50/',\n",
    "                                               startimage_file_path = 'saved_data/llava_saved_data_310/cifar_50/',\n",
    "                                               generator_seed = generator1, num_image_replay=500, \n",
    "                                               folder_name='/scratch/local/ssd/enbo/saved_data/sdxl_llava_i2i_10percentimageprompt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8787116-c25c-4ce0-8c00-619b0ac764a3",
   "metadata": {},
   "source": [
    "## mixed data llava multiple generation image2image 500 real2syn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5e9db5-17f1-4650-b70b-0c4695bbde33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "generator1 = torch.Generator(device=\"cuda\").manual_seed(42)\n",
    "# create_sdxl_data_fixed_prompts_randommultiple(integer_to_name, image_size = (32,32), prompt_file_dict = 'saved_data/llava_saved_data_310/llava_prompt_50/', generator_seed = generator1, num_image_replay=50, folder_name='saved_data/sd_turbo_500images_llava_firstthreeclasses/')\n",
    "\n",
    "create_sdxl_data_img2img_matching_image_prompt_real2syn(specific_integer_to_name, image_size = (32,32),\n",
    "                                               prompt_file_dict = 'saved_data/llava_cifar100_real60_500/',\n",
    "                                startimage_file_path = 'saved_data/cifar_train_all_fortest',\n",
    "                                integer_to_name = integer_to_name,\n",
    "                                dict_syn_to_real_id = real_to_syn_id,\n",
    "                                generator_seed = generator1, num_image_replay=500, \n",
    "                                folder_name='saved_data/sdxl_llava_synfromreal_s8g2') # starting image and prompt from the similar class within the same experience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21dc0d22-2be3-40f3-baf0-b793f16a2908",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "701cda2b",
   "metadata": {},
   "source": [
    "## llava prompt multiple generation image2image imagenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75030617",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator1 = torch.Generator(device=\"cuda\").manual_seed(42)\n",
    "\n",
    "# create_sdxl_data_fixed_prompts_randommultiple_img2img(specific_integer_to_name, image_size = (224,224),\n",
    "                                               prompt_file_dict = 'saved_data/ImageNet/prompt_130_1/',\n",
    "                                               startimage_file_path = 'saved_data/ImageNet/ImageNet_train_renamed_10percent/',\n",
    "                                               generator_seed = generator1, num_image_replay=1300, \n",
    "                                               folder_name='saved_data/ImageNet/ImageNet_sdxl_llavaprompt_3real_i2i')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a3874f",
   "metadata": {},
   "source": [
    "## mixed data llava multiple generation image2image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a7484f",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator1 = torch.Generator(device=\"cuda\").manual_seed(42)\n",
    "# create_sdxl_data_fixed_prompts_randommultiple(integer_to_name, image_size = (32,32), prompt_file_dict = 'saved_data/llava_saved_data_310/llava_prompt_50/', generator_seed = generator1, num_image_replay=50, folder_name='saved_data/sd_turbo_500images_llava_firstthreeclasses/')\n",
    "\n",
    "create_sdxl_data_img2img_matching_image_prompt(integer_to_name, image_size = (32,32),\n",
    "                                               prompt_file_dict = 'saved_data/llava_saved_data_310/llava_prompt_50/',\n",
    "                                               startimage_file_path = 'saved_data/llava_saved_data_310/cifar_50/',\n",
    "                                               generator_seed = generator1, num_image_replay=50, \n",
    "                                               folder_name='saved_data/sd_turbo_i2i_50all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca9cf1d",
   "metadata": {},
   "source": [
    "## mixed data llava multiple generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54324ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator1 = torch.Generator(device=\"cuda\").manual_seed(42)\n",
    "create_sdxl_data_fixed_prompts_randommultiple(specific_integer_to_name, image_size = (32,32), prompt_file_dict = 'saved_data/llava_saved_data_310/llava_prompt_50/', generator_seed = generator1, num_image_replay=500, folder_name='saved_data/sd_turbo_500images_llava_firstthreeclasses/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fece347",
   "metadata": {},
   "source": [
    "## diverse prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2d6a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator1 = torch.Generator(device=\"cuda\").manual_seed(41)\n",
    "create_sdxl_data(specific_integer_to_name, image_size = (32,32), generator_seed = generator1, num_image_replay=500, folder_name='saved_data/sd_turbo_500images/')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "836b976d",
   "metadata": {},
   "source": [
    "## base prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0769c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator1 = torch.Generator(device=\"cuda\").manual_seed(41)\n",
    "create_sdxl_data_baseprompt(specific_integer_to_name, image_size = (32,32), generator_seed = generator1, num_image_replay=500, folder_name='saved_data/sd_turbo_500images_baseprompt/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99caaf8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def count_txt_files(folder_path):\n",
    "    # Ensure the folder exists\n",
    "    if not os.path.exists(folder_path):\n",
    "        print(\"The specified folder does not exist.\")\n",
    "        return 0\n",
    "    \n",
    "    # List all files in the directory\n",
    "    files = os.listdir(folder_path)\n",
    "    \n",
    "    # Filter and count files that end with .txt\n",
    "    txt_files_count = sum(1 for file in files if file.endswith('.txt'))\n",
    "    \n",
    "    return txt_files_count\n",
    "\n",
    "# Specify the folder path here\n",
    "folder_path = 'saved_data/cifar_train500_2syn_i2i_step10/'\n",
    "\n",
    "# Call the function and print the result\n",
    "count = count_txt_files(folder_path)\n",
    "print(f\"There are {count} .txt files in the folder.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8439aabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_and_print_file(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'r') as file:\n",
    "            lines = file.readlines()  # Read all lines in the file\n",
    "            print(len(lines))\n",
    "            for line in lines:\n",
    "                print(line.strip())  # Print each line, stripping newline characters\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file at {file_path} does not exist.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "# Example usage:\n",
    "file_path = 'saved_data/cifar_train500/class36.txt'\n",
    "read_and_print_file(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f0dd39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
