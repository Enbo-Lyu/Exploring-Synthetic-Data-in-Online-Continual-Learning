{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6426a942-e0a4-4894-9c40-c9add6465b7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current default GPU index: 7\n",
      "Current default GPU name: NVIDIA A40\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.set_device(7)\n",
    "if torch.cuda.is_available():\n",
    "    current_gpu = torch.cuda.current_device()\n",
    "    print(f\"Current default GPU index: {current_gpu}\")\n",
    "    print(f\"Current default GPU name: {torch.cuda.get_device_name(current_gpu)}\")\n",
    "else:\n",
    "    print(\"No GPUs available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0f2018f-116a-4f19-8fed-bfc69f0298c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import requests\n",
    "from transformers import AutoProcessor, LlavaForConditionalGeneration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d273f449-5dfc-44b8-9724-db7ea0a9230b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "889a9e76039e4b9c8176bc74b36c50ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BitsAndBytesConfig\n",
    "\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.float16\n",
    ")\n",
    "from transformers import pipeline\n",
    "\n",
    "model_id = \"llava-hf/llava-1.5-7b-hf\"\n",
    "\n",
    "pipe = pipeline(\"image-to-text\", model=model_id, model_kwargs={\"quantization_config\": quantization_config})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20c9dd13-d08e-4d52-96b3-791a86cb63e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USER:  \n",
      "Generate a detailed and concise description less than 77 words of the bee in this image and the overall mood of this image. Focus on major colors, notable objects, and any distinct atmosphere or emotion it conveys.\n",
      "ASSISTANT: The image features a close-up of a yellow apple with a wooden stick in it. The apple is the main focus of the image, and it appears to be ripe and ready to be eaten. The wooden stick adds a rustic touch to the scene, and the overall mood of the image is warm and inviting. The colors in the image are predominantly\n"
     ]
    }
   ],
   "source": [
    "image_path = \"saved_data/cifar_test100/apple0.png\"\n",
    "prompt = \"USER: <image>\\nGenerate a detailed and concise description less than 77 words of the bee in this image and the overall mood of this image. Focus on major colors, notable objects, and any distinct atmosphere or emotion it conveys.\\nASSISTANT:\"\n",
    "image = Image.open(image_path)\n",
    "outputs = pipe(image, prompt=prompt, generate_kwargs={\"max_new_tokens\": 77})\n",
    "print(outputs[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc3056ca-bea2-4b6e-af24-9cc600721f0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USER:  \n",
      "Generate a detailed and concise description less than 77 words of the bee in this image and the overall mood of this image. Focus on major colors, notable objects, and any distinct atmosphere or emotion it conveys.\n",
      "ASSISTANT: The image features a close-up of a yellow apple with a wooden stick in it. The apple is the main focus of the image, and it appears to be ripe and ready to be eaten. The wooden stick adds a rustic touch to the scene, and the overall mood of the image is warm and inviting. The colors in the image are predominantly yellow, which adds to the sense of freshness and naturalness.\n"
     ]
    }
   ],
   "source": [
    "outputs = pipe(image, prompt=prompt, generate_kwargs={\"max_new_tokens\": 200})\n",
    "print(outputs[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "141aa9ab-7d9d-4873-93dc-f8040d894c75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "737c234c-1fc4-4247-87fd-9d0a693370ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_classname(image_path):\n",
    "    # Split the path into parts on the '/'\n",
    "    parts = image_path.split('/')\n",
    "    # The last part is \"apple0.png\", so we take the last element\n",
    "    filename = parts[-1]\n",
    "    # Now we need to remove the number and extension, assuming the format is always classname + number + .png\n",
    "    classname = ''.join([char for char in filename if not char.isdigit()]).replace('.png', '')\n",
    "    return classname\n",
    "\n",
    "def llava_single_pipeline(image_path, prompt):\n",
    "    image = Image.open(image_path)\n",
    "    outputs = pipe(image, prompt=prompt, generate_kwargs={\"max_new_tokens\": 150})\n",
    "    full_response = outputs[0][\"generated_text\"]\n",
    "    # print(full_response)\n",
    "    assistant_index = full_response.find(\"ASSISTANT:\") + len(\"ASSISTANT:\")\n",
    "    caption = full_response[assistant_index:].strip()\n",
    "    return caption\n",
    "\n",
    "\n",
    "def process_images(input_file_path, output_file_path, user_input):\n",
    "    with open(input_file_path, 'r') as file:\n",
    "        image_urls = file.readlines()\n",
    "\n",
    "    with open(output_file_path, 'w') as output_file:\n",
    "        for n, line in enumerate(image_urls):\n",
    "        # for line in tqdm(image_urls, desc=\"Processing Images\", leave=False):\n",
    "            image_url = line.split()[0]\n",
    "            image_url = image_url.strip()  # Remove any extra whitespace\n",
    "            output = llava_single_pipeline(image_url, user_input)\n",
    "            if n % 10 == 0:\n",
    "                print(n)\n",
    "            output_file.write(f\"{image_url}: {output}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc02ffb-c995-4a5a-bd6d-7dba24e16d81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d1d4bf70-69e8-4f2d-94a0-737c938cd8c6",
   "metadata": {},
   "source": [
    "# load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "806a2dc2-0356-43f9-920f-fb0099f625a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "from torch import cat, Tensor\n",
    "from torch.nn import Module\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import Subset, ConcatDataset, TensorDataset\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import SGD\n",
    "from torchvision import datasets, transforms\n",
    "import torch.optim.lr_scheduler # ?\n",
    "from torchvision.transforms import Compose, ToTensor, Normalize, RandomCrop, CenterCrop, RandomHorizontalFlip, Resize\n",
    "from torchvision.transforms.functional import center_crop\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "from torchvision.utils import save_image\n",
    "from torchvision.transforms.functional import pil_to_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "158cadab-c2c1-4594-a9ba-96654302a454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "stats = ((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "\n",
    "transform = transform_train = Compose([\n",
    "    # Resize(224),\n",
    "    # Resize(384),\n",
    "    # RandomHorizontalFlip(),\n",
    "    ToTensor(),\n",
    "    # Normalize(*stats,inplace=True)\n",
    "])\n",
    "\n",
    "# Load the CIFAR-100 training set\n",
    "trainset = torchvision.datasets.CIFAR100(root='data', train=True,download=True, transform=transform)\n",
    "\n",
    "name_list = trainset.classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ca0bb9-ffa3-4a91-9e89-5174a4797a95",
   "metadata": {},
   "source": [
    "# synthetic classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "e953be09-978b-4304-93fe-ab65830733a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n"
     ]
    }
   ],
   "source": [
    "syn_classes = [5, 20, 83, 19, 62, 33, 74, 53, 4, 32, 40, 41, 64, 21, 49, 68, 65, 46, 72, 31, 8, 1, 18, 86, 85, 95, 25, 82, 66, 37, 78, 52, 3, 99, 28, 90, 17, 77, 79, 58]\n",
    "real_classes = list(set([i for i in range(100)]) - set(syn_classes))\n",
    "print(len(real_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "5d0c581c-d892-439b-ad40-0addb9925d08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USER: <image>\n",
      "Generate a long, detailed and concise description of about 77 words using exactly the word 'apple' to describe the apple in this image. Focus on major colors, notable objects, and any distinct atmosphere or emotion the image conveys. Do not use synonyms or related terms for the main item but only using 'apple' to refer it.\n",
      "ASSISTANT:\n"
     ]
    }
   ],
   "source": [
    "prompt = \"USER: <image>\\nGenerate a detailed and concise description less than 77 words of the bee in this image and the overall mood of this image. Focus on major colors, notable objects, and any distinct atmosphere or emotion it conveys.\\nASSISTANT:\"\n",
    "class_name = 'apple'\n",
    "caption_prompt = f\"USER: <image>\\nGenerate a long, detailed and concise description of about 77 words using exactly the word '{class_name}' to describe the {class_name} in this image. Focus on major colors, notable objects, and any distinct atmosphere or emotion the image conveys. Do not use synonyms or related terms for the main item but only using '{class_name}' to refer it.\\nASSISTANT:\"\n",
    "print(caption_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "bcca3078-d25b-445e-a832-9d24faa335da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af94829-1244-46c5-a4ea-c086e52cec04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Each Class:   0%|                                                               | 0/60 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 apple\n",
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n",
      "170\n",
      "180\n",
      "190\n",
      "200\n",
      "210\n",
      "220\n",
      "230\n",
      "240\n",
      "250\n",
      "260\n",
      "270\n",
      "280\n",
      "290\n",
      "300\n",
      "310\n",
      "320\n",
      "330\n",
      "340\n",
      "350\n",
      "360\n",
      "370\n",
      "380\n",
      "390\n",
      "400\n",
      "410\n",
      "420\n",
      "430\n",
      "440\n",
      "450\n",
      "460\n",
      "470\n",
      "480\n",
      "490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Each Class:   2%|▊                                                 | 1/60 [26:57<26:30:59, 1617.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 baby\n",
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n",
      "170\n",
      "180\n",
      "190\n",
      "200\n",
      "210\n",
      "220\n",
      "230\n",
      "240\n",
      "250\n",
      "260\n",
      "270\n",
      "280\n",
      "290\n",
      "300\n",
      "310\n",
      "320\n",
      "330\n",
      "340\n",
      "350\n",
      "360\n",
      "370\n",
      "380\n",
      "390\n",
      "400\n",
      "410\n",
      "420\n",
      "430\n",
      "440\n",
      "450\n",
      "460\n",
      "470\n",
      "480\n",
      "490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Each Class:   3%|█▋                                                | 2/60 [52:02<24:59:44, 1551.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 bee\n",
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n",
      "170\n",
      "180\n",
      "190\n",
      "200\n",
      "210\n",
      "220\n",
      "230\n",
      "240\n",
      "250\n",
      "260\n",
      "270\n",
      "280\n",
      "290\n",
      "300\n",
      "310\n",
      "320\n",
      "330\n",
      "340\n",
      "350\n",
      "360\n",
      "370\n",
      "380\n",
      "390\n",
      "400\n",
      "410\n",
      "420\n",
      "430\n",
      "440\n",
      "450\n",
      "460\n",
      "470\n",
      "480\n",
      "490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Each Class:   5%|██▍                                             | 3/60 [1:18:58<25:01:44, 1580.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 beetle\n",
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n",
      "170\n",
      "180\n",
      "190\n",
      "200\n",
      "210\n",
      "220\n",
      "230\n",
      "240\n",
      "250\n",
      "260\n",
      "270\n",
      "280\n",
      "290\n",
      "300\n",
      "310\n",
      "320\n",
      "330\n",
      "340\n",
      "350\n",
      "360\n",
      "370\n",
      "380\n",
      "390\n",
      "400\n",
      "410\n",
      "420\n",
      "430\n",
      "440\n",
      "450\n",
      "460\n",
      "470\n",
      "480\n",
      "490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Each Class:   7%|███▏                                            | 4/60 [1:45:48<24:46:09, 1592.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 bottle\n",
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n",
      "170\n",
      "180\n",
      "190\n",
      "200\n",
      "210\n",
      "220\n",
      "230\n",
      "240\n",
      "250\n",
      "260\n",
      "270\n",
      "280\n",
      "290\n",
      "300\n",
      "310\n",
      "320\n",
      "330\n",
      "340\n",
      "350\n",
      "360\n",
      "370\n",
      "380\n",
      "390\n",
      "400\n",
      "410\n",
      "420\n",
      "430\n",
      "440\n",
      "450\n",
      "460\n",
      "470\n",
      "480\n",
      "490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Each Class:   8%|████                                            | 5/60 [2:12:39<24:25:46, 1599.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 bowl\n",
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n",
      "170\n",
      "180\n",
      "190\n",
      "200\n",
      "210\n",
      "220\n",
      "230\n",
      "240\n",
      "250\n",
      "260\n",
      "270\n",
      "280\n",
      "290\n",
      "300\n",
      "310\n",
      "320\n",
      "330\n",
      "340\n",
      "350\n",
      "360\n",
      "370\n",
      "380\n",
      "390\n",
      "400\n",
      "410\n",
      "420\n",
      "430\n",
      "440\n",
      "450\n",
      "460\n",
      "470\n",
      "480\n",
      "490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Each Class:  10%|████▊                                           | 6/60 [2:39:43<24:06:43, 1607.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 boy\n",
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n",
      "170\n",
      "180\n",
      "190\n",
      "200\n",
      "210\n",
      "220\n",
      "230\n",
      "240\n",
      "250\n",
      "260\n",
      "270\n",
      "280\n",
      "290\n",
      "300\n",
      "310\n",
      "320\n",
      "330\n",
      "340\n",
      "350\n",
      "360\n",
      "370\n",
      "380\n",
      "390\n",
      "400\n",
      "410\n",
      "420\n",
      "430\n",
      "440\n",
      "450\n",
      "460\n",
      "470\n",
      "480\n",
      "490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Each Class:  12%|█████▌                                          | 7/60 [3:03:58<22:55:51, 1557.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 bridge\n",
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n",
      "170\n",
      "180\n",
      "190\n",
      "200\n",
      "210\n",
      "220\n",
      "230\n",
      "240\n",
      "250\n",
      "260\n",
      "270\n",
      "280\n",
      "290\n",
      "300\n",
      "310\n",
      "320\n",
      "330\n",
      "340\n",
      "350\n",
      "360\n",
      "370\n",
      "380\n",
      "390\n",
      "400\n",
      "410\n",
      "420\n",
      "430\n",
      "440\n",
      "450\n",
      "460\n",
      "470\n",
      "480\n",
      "490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Each Class:  13%|██████▍                                         | 8/60 [3:32:14<23:08:18, 1601.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 bus\n",
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n",
      "170\n",
      "180\n",
      "190\n",
      "200\n",
      "210\n",
      "220\n",
      "230\n",
      "240\n",
      "250\n",
      "260\n",
      "270\n",
      "280\n",
      "290\n",
      "300\n",
      "310\n",
      "320\n",
      "330\n",
      "340\n",
      "350\n",
      "360\n",
      "370\n",
      "380\n",
      "390\n",
      "400\n",
      "410\n",
      "420\n",
      "430\n",
      "440\n",
      "450\n",
      "460\n",
      "470\n",
      "480\n",
      "490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Each Class:  15%|███████▏                                        | 9/60 [3:57:53<22:24:50, 1582.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 butterfly\n",
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n",
      "170\n",
      "180\n",
      "190\n",
      "200\n",
      "210\n",
      "220\n",
      "230\n",
      "240\n",
      "250\n",
      "260\n",
      "270\n",
      "280\n",
      "290\n",
      "300\n",
      "310\n",
      "320\n",
      "330\n",
      "340\n",
      "350\n",
      "360\n",
      "370\n",
      "380\n",
      "390\n",
      "400\n",
      "410\n",
      "420\n",
      "430\n",
      "440\n",
      "450\n",
      "460\n",
      "470\n",
      "480\n",
      "490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Each Class:  17%|███████▊                                       | 10/60 [4:25:15<22:13:47, 1600.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 camel\n",
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n",
      "170\n",
      "180\n",
      "190\n",
      "200\n",
      "210\n",
      "220\n",
      "230\n",
      "240\n",
      "250\n",
      "260\n",
      "270\n",
      "280\n",
      "290\n",
      "300\n",
      "310\n",
      "320\n",
      "330\n",
      "340\n",
      "350\n",
      "360\n",
      "370\n",
      "380\n",
      "390\n",
      "400\n",
      "410\n",
      "420\n",
      "430\n",
      "440\n",
      "450\n",
      "460\n",
      "470\n",
      "480\n",
      "490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Each Class:  18%|████████▌                                      | 11/60 [4:53:24<22:09:17, 1627.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 can\n",
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n",
      "170\n",
      "180\n",
      "190\n",
      "200\n",
      "210\n",
      "220\n",
      "230\n",
      "240\n",
      "250\n",
      "260\n",
      "270\n",
      "280\n",
      "290\n",
      "300\n",
      "310\n",
      "320\n",
      "330\n",
      "340\n",
      "350\n",
      "360\n",
      "370\n",
      "380\n",
      "390\n",
      "400\n",
      "410\n",
      "420\n",
      "430\n",
      "440\n",
      "450\n",
      "460\n",
      "470\n",
      "480\n",
      "490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Each Class:  20%|█████████▍                                     | 12/60 [5:18:58<21:19:19, 1599.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22 clock\n",
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n",
      "170\n",
      "180\n",
      "190\n",
      "200\n",
      "210\n",
      "220\n",
      "230\n",
      "240\n",
      "250\n",
      "260\n",
      "270\n",
      "280\n",
      "290\n",
      "300\n",
      "310\n",
      "320\n",
      "330\n",
      "340\n",
      "350\n",
      "360\n",
      "370\n",
      "380\n",
      "390\n",
      "400\n",
      "410\n",
      "420\n",
      "430\n",
      "440\n",
      "450\n",
      "460\n",
      "470\n",
      "480\n",
      "490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Each Class:  22%|██████████▏                                    | 13/60 [5:46:51<21:10:16, 1621.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23 cloud\n",
      "0\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "image_save_dir = 'saved_data/cifar_train_all_fortest'\n",
    "\n",
    "# for i in real_classes:\n",
    "for i in tqdm(real_classes, desc=\"Processing Each Class\"):\n",
    "    class_name = name_list[i]\n",
    "    print(i, class_name)\n",
    "    current_class_txt_path = os.path.join(image_save_dir, f\"class{i}.txt\")\n",
    "    # print(current_class_txt_path)\n",
    "    output_dict = 'saved_data/llava_cifar100_real60_500'\n",
    "    if not os.path.exists(output_dict):\n",
    "        os.makedirs(output_dict)\n",
    "    output_path = os.path.join(output_dict, f'class{i}.txt')\n",
    "    # caption_prompt = f\"USER: <image>\\nGenerate a detailed and concise description less than 77 words of the {class_name} in this image and the overall mood of this image. Focus on major colors, notable objects, and any distinct atmosphere or emotion it conveys.\\nASSISTANT:\"\n",
    "    caption_prompt = f\"USER: <image>\\nGenerate a long, detailed and concise description of about 77 words using exactly the word '{class_name}' to describe the {class_name} in this image. Focus on major colors, notable objects, and any distinct atmosphere or emotion the image conveys. Do not use synonyms or related terms for the main item but only using '{class_name}' to refer it.\\nASSISTANT:\"\n",
    "\n",
    "    process_images(current_class_txt_path, output_path, caption_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f89314-082a-4282-9752-648b3dc6fbd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_txt_files(directory):\n",
    "    \"\"\"\n",
    "    Counts the number of .txt files in the specified directory.\n",
    "\n",
    "    Args:\n",
    "    directory (str): The path to the directory to search for .txt files.\n",
    "\n",
    "    Returns:\n",
    "    int: The number of .txt files in the directory.\n",
    "    \"\"\"\n",
    "    txt_count = 0\n",
    "    # List all files and directories in the specified directory\n",
    "    for entry in os.listdir(directory):\n",
    "        # Construct full path\n",
    "        full_path = os.path.join(directory, entry)\n",
    "        # Check if it's a file with a .txt extension\n",
    "        if os.path.isfile(full_path) and entry.endswith('.png'):\n",
    "            txt_count += 1\n",
    "    \n",
    "    return txt_count\n",
    "\n",
    "output_folder = 'saved_data/cifar_train_all_fortest'\n",
    "count = count_txt_files(output_folder)\n",
    "print(f\"There are {count} .txt files in the folder.\")\n",
    "# count = count_png_files(output_folder)\n",
    "# print(f\"There are {count} .png files in the folder.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5ff9b5a2-a9df-4277-ba14-e657438ed664",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in /homes/55/enbo/miniconda3/envs/llava/lib/python3.10/site-packages (4.66.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1663e05a-5ec0-4109-85ea-724e039d3ea5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
