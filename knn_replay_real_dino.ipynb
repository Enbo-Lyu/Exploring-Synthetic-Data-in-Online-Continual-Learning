{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current default GPU index: 2\n",
      "Current default GPU name: NVIDIA A40\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.set_device(2)\n",
    "if torch.cuda.is_available():\n",
    "    current_gpu = torch.cuda.current_device()\n",
    "    print(f\"Current default GPU index: {current_gpu}\")\n",
    "    print(f\"Current default GPU name: {torch.cuda.get_device_name(current_gpu)}\")\n",
    "else:\n",
    "    print(\"No GPUs available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tqhW7Y0auSg3"
   },
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "uHBgOTv8-Kln"
   },
   "outputs": [],
   "source": [
    "# all imports\n",
    "\n",
    "# buffer\n",
    "from collections import defaultdict\n",
    "import random\n",
    "from abc import ABC, abstractmethod\n",
    "from typing import (\n",
    "    Any,\n",
    "    Dict,\n",
    "    Generic,\n",
    "    Optional,\n",
    "    List,\n",
    "    TYPE_CHECKING,\n",
    "    Set,\n",
    "    TypeVar,\n",
    ")\n",
    "\n",
    "from avalanche.benchmarks.utils import (\n",
    "    classification_subset,\n",
    "    AvalancheDataset,\n",
    ")\n",
    "from avalanche.models import FeatureExtractorBackbone\n",
    "# from ..benchmarks.utils.utils import concat_datasets\n",
    "from avalanche.benchmarks.utils import concat_datasets\n",
    "from avalanche.training.storage_policy import ReservoirSamplingBuffer, BalancedExemplarsBuffer, ClassBalancedBuffer\n",
    "\n",
    "from avalanche.training.storage_policy import ParametricBuffer, RandomExemplarsSelectionStrategy, ExemplarsBuffer, ExperienceBalancedBuffer\n",
    "from avalanche.benchmarks.utils.data_loader import ReplayDataLoader\n",
    "from avalanche.training.plugins import SupervisedPlugin\n",
    "from typing import Optional, TYPE_CHECKING\n",
    "\n",
    "from avalanche.benchmarks.utils import concat_classification_datasets\n",
    "from avalanche.training.plugins.strategy_plugin import SupervisedPlugin\n",
    "\n",
    "if TYPE_CHECKING:\n",
    "    from avalanche.training.templates import SupervisedTemplate, BaseSGDTemplate\n",
    "\n",
    "# dataset\n",
    "from avalanche.benchmarks import SplitMNIST, SplitCIFAR100\n",
    "from avalanche.benchmarks.classic import SplitCIFAR100\n",
    "from avalanche.benchmarks.classic import SplitCIFAR10\n",
    "from avalanche.benchmarks.utils.data_loader import GroupBalancedDataLoader, ReplayDataLoader\n",
    "from avalanche.benchmarks.generators import nc_benchmark, ni_benchmark\n",
    "from avalanche.benchmarks.generators import filelist_benchmark, dataset_benchmark, \\\n",
    "                                            tensors_benchmark, paths_benchmark\n",
    "\n",
    "from avalanche.logging import InteractiveLogger, TensorboardLogger, \\\n",
    "    WandBLogger, TextLogger, TensorboardLogger\n",
    "\n",
    "from avalanche.training.plugins import EvaluationPlugin\n",
    "from avalanche.evaluation.metrics import forgetting_metrics, accuracy_metrics, loss_metrics\n",
    "\n",
    "from avalanche.training.plugins.checkpoint import CheckpointPlugin, \\\n",
    "    FileSystemCheckpointStorage\n",
    "from avalanche.training.determinism.rng_manager import RNGManager\n",
    "from avalanche.training import Naive, CWRStar, Replay, GDumb, \\\n",
    "    Cumulative, LwF, GEM, AGEM, EWC, AR1, ICaRL\n",
    "from avalanche.models import SimpleMLP\n",
    "from avalanche.training.plugins import ReplayPlugin\n",
    "from types import SimpleNamespace\n",
    "from avalanche.training.storage_policy import ParametricBuffer, RandomExemplarsSelectionStrategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Znp5LYsI-myD"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy import inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "fzOy2HmlWQnX"
   },
   "outputs": [],
   "source": [
    "# all imports\n",
    "\n",
    "import torch\n",
    "import os\n",
    "from torch import cat, Tensor\n",
    "from torch.nn import Module\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import Subset, ConcatDataset, TensorDataset\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import SGD\n",
    "from torchvision import datasets, transforms\n",
    "import torch.optim.lr_scheduler # ?\n",
    "from torchvision.transforms import Compose, ToTensor, Normalize, RandomCrop, CenterCrop, RandomHorizontalFlip, Resize\n",
    "from torchvision.transforms.functional import center_crop\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "from torchvision.utils import save_image\n",
    "from torchvision.transforms.functional import pil_to_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v0sf0FvHf43e",
    "outputId": "88cee04e-55dd-4a4b-8372-1f90a50ac620"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "stats = ((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "\n",
    "transform = transform_train = Compose([\n",
    "    # Resize(224),\n",
    "    # Resize(384),\n",
    "    # RandomHorizontalFlip(),\n",
    "    ToTensor(),\n",
    "    # Normalize(*stats,inplace=True)\n",
    "])\n",
    "\n",
    "# Load the CIFAR-100 training set\n",
    "trainset = torchvision.datasets.CIFAR100(root='data', train=True,\n",
    "                                         download=True, transform=transform)\n",
    "\n",
    "name_list = trainset.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 210
    },
    "id": "d0rW8AbrJ3VQ",
    "outputId": "0b5eb9c8-b53a-44f8-c006-b4c06a7c3e75"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "telephone maple_tree   sea beetle\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True)\n",
    "\n",
    "# Function to show images\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5  # unnormalize if Normalize was used in transform\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "# Get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# Show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# Print labels\n",
    "print(' '.join('%5s' % trainset.classes[labels[j]] for j in range(4)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eUIbhWRql_oQ",
    "outputId": "17a0dfbd-270a-4696-b95c-dd5804b69f85"
   },
   "outputs": [],
   "source": [
    "\n",
    "def tensor_to_pil(image_tensor):\n",
    "    return transforms.ToPILImage()(image_tensor).convert(\"RGB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ptMPtw0fYuhS",
    "outputId": "92b65eae-362e-4fea-a093-5881fecc8796"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.transforms import Compose, Resize, RandomHorizontalFlip, ToTensor\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "\n",
    "def save_cifar100_random_replay(dataset, num_images_per_class, save_dir):\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    torch.manual_seed(41)\n",
    "\n",
    "    saved_counts = {label: 0 for label in range(100)}  # Initialize saved image count for each class\n",
    "    \n",
    "    transform_to_tensor = transforms.ToTensor()\n",
    "    \n",
    "    indices = torch.randperm(len(dataset)).tolist()\n",
    "    for idx in indices:\n",
    "        image, label = dataset[idx]\n",
    "        image_tensor = transform_to_tensor(image)\n",
    "\n",
    "        # Skip saving if this class already has the desired number of images saved\n",
    "        if saved_counts[label] >= num_images_per_class:\n",
    "            continue\n",
    "\n",
    "        class_name = dataset.classes[label]\n",
    "        image_path = os.path.join(save_dir, f'{class_name}_{saved_counts[label]}.png')\n",
    "        save_image(image_tensor, image_path)\n",
    "        saved_counts[label] += 1\n",
    "\n",
    "        # Check if we have finished saving max_images for all classes\n",
    "        class_file_path = os.path.join(save_dir, f\"class{label}.txt\")\n",
    "        with open(class_file_path, \"a\") as file:\n",
    "            file.write(f\"{image_path} {label}\\n\")\n",
    "\n",
    "        # Check if we have finished saving the specified number of images for all classes\n",
    "        if all(count >= num_images_per_class for count in saved_counts.values()):\n",
    "            break\n",
    "\n",
    "    print(f\"Saved {num_images_per_class} images per class from the CIFAR-100 training dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9rlEluD6j2Zr",
    "outputId": "91c26ac2-c1ce-477e-ec44-f679ca9e8afe"
   },
   "outputs": [],
   "source": [
    "# save_cifar100_random_replay(trainset, 50, 'saved_data/cifar0411_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "TGTjnkg03Dnn"
   },
   "outputs": [],
   "source": [
    "integer_to_name = {i: name for i, name in enumerate(name_list)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o4feAAu63PEe",
    "outputId": "30d6c1d5-f867-444b-98ef-f77725a5de58"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 apple\n"
     ]
    }
   ],
   "source": [
    "for id in integer_to_name:\n",
    "    print(id, integer_to_name[id])\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2VUd1jnlL4vV"
   },
   "source": [
    "# Data transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "ZyQi87koaOjd"
   },
   "outputs": [],
   "source": [
    "# !pip install pytorch_pretrained_vit\n",
    "\n",
    "\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# ?\n",
    "\n",
    "from avalanche.benchmarks.classic import SplitCIFAR100\n",
    "from avalanche.benchmarks.classic import SplitCIFAR10\n",
    "\n",
    "from avalanche.benchmarks.generators import nc_benchmark, ni_benchmark\n",
    "\n",
    "from avalanche.benchmarks.generators import filelist_benchmark, dataset_benchmark, \\\n",
    "                                            tensors_benchmark, paths_benchmark\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "DkwtwPTByTNd"
   },
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from torchvision.transforms import Compose, ToTensor, Normalize, RandomCrop, RandomHorizontalFlip, Resize\n",
    "import os\n",
    "# stats = ((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "stats = ((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "transform_train = Compose([\n",
    "    Resize((224, 224)),\n",
    "    RandomHorizontalFlip(),\n",
    "    ToTensor(),\n",
    "    Normalize(*stats,inplace=True)\n",
    "])\n",
    "\n",
    "transform_test = Compose([\n",
    "    Resize((224,224)),\n",
    "    ToTensor(),\n",
    "    Normalize(*stats,inplace=True)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "a5YNVSvRJH6n"
   },
   "outputs": [],
   "source": [
    "from avalanche.logging import InteractiveLogger, TextLogger, TensorboardLogger\n",
    "from avalanche.logging import InteractiveLogger, TensorboardLogger, \\\n",
    "    WandBLogger, TextLogger\n",
    "# log to Tensorboard\n",
    "tb_logger = TensorboardLogger()\n",
    "\n",
    "# log to text file\n",
    "text_logger = TextLogger(open('logs/test.txt', 'w'))\n",
    "\n",
    "# print to stdout\n",
    "interactive_logger = InteractiveLogger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "Qx3UrGFcJH6o"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/homes/55/enbo/miniconda3/envs/thesis3.7/lib/python3.7/site-packages/avalanche/training/plugins/evaluation.py:68: UserWarning: No loggers specified, metrics will not be logged\n",
      "  warnings.warn(\"No loggers specified, metrics will not be logged\")\n"
     ]
    }
   ],
   "source": [
    "# evaluation\n",
    "from avalanche.training.plugins import EvaluationPlugin\n",
    "from avalanche.evaluation.metrics import forgetting_metrics, accuracy_metrics, loss_metrics, class_accuracy_metrics\n",
    "\n",
    "# The evaluation plugin manages the metrics computation.\n",
    "eval_plugin = EvaluationPlugin(\n",
    "    accuracy_metrics(minibatch=False, epoch=True, experience=True, stream=True),\n",
    "    loss_metrics(minibatch=False, epoch=True, experience=True, stream=True),\n",
    "    class_accuracy_metrics(minibatch=False, epoch=False, epoch_running=False, experience=False, stream=True),\n",
    "    # forgetting_metrics(experience=True, stream=True),\n",
    "#     loggers=[interactive_logger, text_logger, tb_logger]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "f3UKvdtpc9tL"
   },
   "outputs": [],
   "source": [
    "from avalanche.training.plugins.checkpoint import CheckpointPlugin, \\\n",
    "    FileSystemCheckpointStorage\n",
    "from avalanche.training.determinism.rng_manager import RNGManager\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WRjpqXv9dR9V",
    "outputId": "c82c7a66-91d8-4f23-d9bc-ef1bf3a33cfd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "RNGManager.set_random_seeds(1234)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)\n",
    "\n",
    "checkpoint_plugin = CheckpointPlugin(\n",
    "    FileSystemCheckpointStorage(\n",
    "        directory='./checkpoints/task_cifar',\n",
    "    ),\n",
    "    map_location=device\n",
    ")\n",
    "\n",
    "# Load checkpoint (if exists in the given storage)\n",
    "# If it does not exist, strategy will be None and initial_exp will be 0\n",
    "strategy, initial_exp = checkpoint_plugin.load_checkpoint_if_exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "R-twpACd-97s"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "def combine_files_with_numbers(folder, file_initial, numbers, output_folder):\n",
    "    \"\"\"use to get the data with label in the training experience\"\"\"\n",
    "    combined_content = \"\"  # Initialize an empty string to store combined content\n",
    "    # Compile a set of filenames to look for, based on the list of numbers\n",
    "    filenames_to_look_for = {file_initial + f\"{number}.txt\" for number in numbers}\n",
    "\n",
    "    # Iterate over each file in the specified folder\n",
    "    for file in os.listdir(folder):\n",
    "        # Check if the file name matches exactly any in our set of filenames to look for\n",
    "        if file in filenames_to_look_for:\n",
    "            # Open and read the file, then add its content to the combined_content string\n",
    "            with open(os.path.join(folder, file), 'r') as f:\n",
    "                combined_content += f.read()  # Add a newline character after each file's content for better separation\n",
    "\n",
    "    joined_string = '_'.join(str(integer) for integer in numbers)\n",
    "\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    output_file_path = output_folder +file_initial+ 'combined' + '_' + joined_string + '.txt'\n",
    "    print(output_file_path)\n",
    "    with open(output_file_path, 'w') as f:\n",
    "        f.write(combined_content)\n",
    "\n",
    "def shuffle_text_file_lines(file_path):\n",
    "    \"\"\"\n",
    "    Shuffles the lines in a text file.\n",
    "\n",
    "    Parameters:\n",
    "    - file_path: Path to the text file to shuffle.\n",
    "    \"\"\"\n",
    "    # Read the lines from the file\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    # Shuffle the lines\n",
    "    random.shuffle(lines)\n",
    "\n",
    "    # Write the shuffled lines back to the file\n",
    "    with open(file_path, 'w') as file:\n",
    "        file.writelines(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ux_kentvVEVO"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mANAU2ll7aUy"
   },
   "source": [
    "# customize replay plugin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "5q8wDhlP8nBg"
   },
   "outputs": [],
   "source": [
    "class CustomReplay_SD(SupervisedPlugin):\n",
    "    def __init__(\n",
    "        self,\n",
    "        # sd_data,\n",
    "        mem_size: int = 200,\n",
    "        batch_size: Optional[int] = None,\n",
    "        batch_size_mem: Optional[int] = None,\n",
    "        task_balanced_dataloader: bool = False,\n",
    "        storage_policy: Optional[\"ExemplarsBuffer\"] = None,\n",
    "        image_folder = None\n",
    "        # The policy that controls how to add new exemplars in memory\n",
    "                        #\n",
    "    ):\n",
    "        super().__init__()\n",
    "        # self.sd_data = sd_data\n",
    "        self.mem_size = mem_size\n",
    "        self.batch_size = batch_size\n",
    "        self.batch_size_mem = batch_size_mem\n",
    "        self.task_balanced_dataloader = task_balanced_dataloader\n",
    "\n",
    "        self.storage_policy = storage_policy\n",
    "        self.image_folder = image_folder\n",
    "        assert storage_policy.max_size == self.mem_size\n",
    "\n",
    "        if storage_policy is not None:  # Use other storage policy\n",
    "            self.storage_policy = storage_policy\n",
    "            assert storage_policy.max_size == self.mem_size\n",
    "        else:  # Default\n",
    "            self.storage_policy = ExperienceBalancedBuffer(\n",
    "                max_size=self.mem_size, adaptive_size=True\n",
    "            )\n",
    "\n",
    "    def before_training_exp(\n",
    "        self,\n",
    "        strategy: \"SupervisedTemplate\",\n",
    "        num_workers: int = 0,\n",
    "        shuffle: bool = True,\n",
    "        drop_last: bool = False,\n",
    "        **kwargs\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Dataloader to build batches containing examples from both memories and\n",
    "        the training dataset\n",
    "        \"\"\"\n",
    "        if len(self.storage_policy.buffer) == 0:\n",
    "            return\n",
    "\n",
    "#         batch_size = self.batch_size\n",
    "#         if batch_size is None:\n",
    "#             batch_size = strategy.train_mb_size\n",
    "\n",
    "        batch_size_mem = self.batch_size_mem\n",
    "        if batch_size_mem is None:\n",
    "            batch_size_mem = strategy.train_mb_size\n",
    "\n",
    "        assert strategy.adapted_dataset is not None\n",
    "        strategy.dataloader = ReplayDataLoader(\n",
    "            strategy.adapted_dataset,\n",
    "            self.storage_policy.buffer,\n",
    "            batch_size=strategy.train_mb_size,\n",
    "            num_workers=num_workers,\n",
    "            shuffle=shuffle,\n",
    "        )\n",
    "\n",
    "    def after_training_exp(self, strategy: \"SupervisedTemplate\", **kwargs):\n",
    "        \"\"\" We update the buffer after the experience.\n",
    "            You can use a different callback to update the buffer in a different place\n",
    "        \"\"\"\n",
    "        print(\"Buffer update.\")\n",
    "        buffer_size = len(self.storage_policy.buffer)\n",
    "        print(\"buffer size: \" + str(buffer_size))\n",
    "        num_class = len(self.storage_policy.buffer_datasets)\n",
    "        print(\"current class number in replay buffer: \" + str(num_class))\n",
    "        # self.storage_policy.update(strategy, **kwargs)\n",
    "\n",
    "        # print(type(strategy.experience))\n",
    "\n",
    "        current_experience = strategy.experience\n",
    "\n",
    "        current_classes = current_experience.classes_in_this_experience\n",
    "        print(current_classes)\n",
    "        # create the combined txt file with current classes\n",
    "        print(\"start to combine files...\")\n",
    "        combine_files_with_numbers(\n",
    "            self.image_folder,\n",
    "            'class',\n",
    "            current_classes,\n",
    "            self.image_folder + 'combined/')\n",
    "        joined_string = '_'.join(str(integer) for integer in current_classes)\n",
    "        combined_file_name = self.image_folder + 'combined/' + 'class' + 'combined' + '_' + joined_string + '.txt'\n",
    "\n",
    "        cur_train_set = [combined_file_name]\n",
    "\n",
    "        print(\"start generating sd data scenario...\")\n",
    "        sd_dataset_scenario =  filelist_benchmark(\n",
    "                                None,\n",
    "                                train_file_lists = cur_train_set, # train\n",
    "                                test_file_lists = [], # test\n",
    "                                task_labels = [0],\n",
    "                                # complete_test_set_only=True,\n",
    "                                train_transform=transform_train,\n",
    "                            eval_transform=transform_train\n",
    "                            )\n",
    "        sd_data = SimpleNamespace(experience = sd_dataset_scenario.train_stream[0])\n",
    "        # storage_p.update(strategy_state)\n",
    "\n",
    "        print(\"start updating sd data into buffer\")\n",
    "        self.storage_policy.update(sd_data, **kwargs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SVzdt5GsBMxC"
   },
   "source": [
    "# experiment 20 tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "NjP1BTXZBMxC"
   },
   "outputs": [],
   "source": [
    "# training\n",
    "from avalanche.training import Naive, CWRStar, Replay, GDumb, \\\n",
    "    Cumulative, LwF, GEM, AGEM, EWC, AR1\n",
    "\n",
    "# strategies\n",
    "from avalanche.models import SimpleMLP\n",
    "from torch.optim import SGD\n",
    "from torch.nn import CrossEntropyLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "6ztRwlSmBMxD"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /homes/55/enbo/.cache/torch/hub/facebookresearch_dino_main\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "# resnet50 = torch.hub.load('ckpt/dino_resnet50_pretrain.pth', 'dino_resnet50')\n",
    "resnet_model = torch.hub.load('facebookresearch/dino:main', 'dino_resnet50')\n",
    "resnet_model.fc = nn.Identity()\n",
    "\n",
    "for param in resnet_model.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "\n",
    "# # Step 2: Create a new network class with an additional linear layer\n",
    "# class CustomNetwork(nn.Module):\n",
    "#     def __init__(self, pretrained_model, num_classes):\n",
    "#         super(CustomNetwork, self).__init__()\n",
    "#         self.pretrained_model = pretrained_model\n",
    "#         self.fc = nn.Linear(2048, num_classes)  # New linear layer with trainable weights\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         # Extract features using the pre-trained model\n",
    "#         features = self.pretrained_model(x)\n",
    "#         # Flatten the output for the linear layer if not already flattened\n",
    "#         features = torch.flatten(features, 1)\n",
    "#         # Pass features through the new linear layer\n",
    "#         output = self.fc(features)\n",
    "#         return output\n",
    "\n",
    "# # Step 3: Initialize the new network with the desired number of output classes\n",
    "# num_classes = 100  # Example: 10 classes for a new classification task\n",
    "# resnet_model = CustomNetwork(resnet_model, num_classes)\n",
    "\n",
    "# # The only parameters that are trainable are those of the new linear layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "from avalanche.training.templates import SupervisedTemplate\n",
    "from avalanche.benchmarks.utils import AvalancheDataset\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from avalanche.training.plugins import SupervisedPlugin\n",
    "from avalanche.benchmarks.utils.data_loader import ReplayDataLoader\n",
    "from typing import Optional\n",
    "\n",
    "class DINOFeatureExtractor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Load the pre-trained DINO model\n",
    "        self.feature_extractor = torch.hub.load('facebookresearch/dino:main', 'dino_resnet50')\n",
    "        # Remove the head or adapt it to return features instead of logits\n",
    "        self.feature_extractor.fc = nn.Identity()\n",
    "        for param in self.feature_extractor.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Extract features using the DINO backbone\n",
    "        return self.feature_extractor(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "lW0jcAVOBMxD"
   },
   "outputs": [],
   "source": [
    "# training\n",
    "from avalanche.training import Naive, CWRStar, Replay, GDumb, \\\n",
    "    Cumulative, LwF, GEM, AGEM, EWC, AR1\n",
    "\n",
    "# strategies\n",
    "from avalanche.models import SimpleMLP\n",
    "from torch.optim import SGD\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from avalanche.training.plugins import ReplayPlugin\n",
    "\n",
    "from types import SimpleNamespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gIAHFiAiBMxD",
    "outputId": "17846555-d146-499f-da2a-caceb232aee3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "benchmark = SplitCIFAR100(n_experiences=20,\n",
    "                          train_transform=transform_train,\n",
    "                          eval_transform = transform_test,\n",
    "                          seed = 41\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC\n",
    "from typing import TypeVar, Generic\n",
    "from typing import TYPE_CHECKING\n",
    "\n",
    "if TYPE_CHECKING:\n",
    "    from avalanche.training.templates.base import BaseTemplate\n",
    "\n",
    "CallbackResult = TypeVar(\"CallbackResult\")\n",
    "Template = TypeVar(\"Template\", bound=\"BaseTemplate\")\n",
    "\n",
    "\n",
    "class BasePlugin(Generic[Template], ABC):\n",
    "    \"\"\"ABC for BaseTemplate plugins.\n",
    "\n",
    "    A plugin is simply an object implementing some strategy callbacks.\n",
    "    Plugins are called automatically during the strategy execution.\n",
    "\n",
    "    Callbacks provide access before/after each phase of the execution.\n",
    "    In general, for each method of the training and evaluation loops,\n",
    "    `StrategyCallbacks`\n",
    "    provide two functions `before_{method}` and `after_{method}`, called\n",
    "    before and after the method, respectively.\n",
    "    Therefore plugins can \"inject\" additional code by implementing callbacks.\n",
    "    Each callback has a `strategy` argument that gives access to the state.\n",
    "\n",
    "    In Avalanche, callbacks are used to implement continual strategies, metrics\n",
    "    and loggers.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "    def before_training(self, strategy: Template, *args, **kwargs):\n",
    "        \"\"\"Called before `train` by the `BaseTemplate`.\"\"\"\n",
    "        pass\n",
    "\n",
    "    def before_training_exp(self, strategy: Template, *args, **kwargs):\n",
    "        \"\"\"Called before `train_exp` by the `BaseTemplate`.\"\"\"\n",
    "        pass\n",
    "\n",
    "    def after_training_exp(self, strategy: Template, *args, **kwargs):\n",
    "        \"\"\"Called after `train_exp` by the `BaseTemplate`.\"\"\"\n",
    "        pass\n",
    "\n",
    "    def after_training(self, strategy: Template, *args, **kwargs):\n",
    "        \"\"\"Called after `train` by the `BaseTemplate`.\"\"\"\n",
    "        pass\n",
    "\n",
    "    def before_eval(\n",
    "        self, strategy: Template, *args, **kwargs\n",
    "    ) -> CallbackResult:\n",
    "        \"\"\"Called before `eval` by the `BaseTemplate`.\"\"\"\n",
    "        pass\n",
    "\n",
    "    def before_eval_exp(\n",
    "        self, strategy: Template, *args, **kwargs\n",
    "    ) -> CallbackResult:\n",
    "        \"\"\"Called before `eval_exp` by the `BaseTemplate`.\"\"\"\n",
    "        pass\n",
    "\n",
    "    def after_eval_exp(\n",
    "        self, strategy: Template, *args, **kwargs\n",
    "    ) -> CallbackResult:\n",
    "        \"\"\"Called after `eval_exp` by the `BaseTemplate`.\"\"\"\n",
    "        pass\n",
    "\n",
    "    def after_eval(self, strategy: Template, *args, **kwargs) -> CallbackResult:\n",
    "        \"\"\"Called after `eval` by the `BaseTemplate`.\"\"\"\n",
    "        pass\n",
    "\n",
    "class Knn_DinoPlugin(BasePlugin[Template], ABC):\n",
    "    \"\"\"ABC for BaseSGDTemplate plugins.\n",
    "\n",
    "    See `BaseSGDTemplate` for complete description of the train/eval loop.\n",
    "    \"\"\"\n",
    "\n",
    "    def before_training_epoch(\n",
    "        self, strategy: Template, *args, **kwargs\n",
    "    ) -> CallbackResult:\n",
    "        \"\"\"Called before `train_epoch` by the `BaseTemplate`.\"\"\"\n",
    "        pass\n",
    "\n",
    "    def before_training_iteration(\n",
    "        self, strategy: Template, *args, **kwargs\n",
    "    ) -> CallbackResult:\n",
    "        \"\"\"Called before the start of a training iteration by the\n",
    "        `BaseTemplate`.\"\"\"\n",
    "        pass\n",
    "\n",
    "    def before_forward(\n",
    "        self, strategy: Template, *args, **kwargs\n",
    "    ) -> CallbackResult:\n",
    "        \"\"\"Called before `model.forward()` by the `BaseTemplate`.\"\"\"\n",
    "        pass\n",
    "\n",
    "    def after_forward(\n",
    "        self, strategy: Template, *args, **kwargs\n",
    "    ) -> CallbackResult:\n",
    "        \"\"\"Called after `model.forward()` by the `BaseTemplate`.\"\"\"\n",
    "        pass\n",
    "\n",
    "    def before_backward(\n",
    "        self, strategy: Template, *args, **kwargs\n",
    "    ) -> CallbackResult:\n",
    "        \"\"\"Called before `criterion.backward()` by the `BaseTemplate`.\"\"\"\n",
    "        pass\n",
    "\n",
    "    def after_backward(\n",
    "        self, strategy: Template, *args, **kwargs\n",
    "    ) -> CallbackResult:\n",
    "        \"\"\"Called after `criterion.backward()` by the `BaseTemplate`.\"\"\"\n",
    "        pass\n",
    "\n",
    "    def after_training_iteration(\n",
    "        self, strategy: Template, *args, **kwargs\n",
    "    ) -> CallbackResult:\n",
    "        \"\"\"Called after the end of a training iteration by the\n",
    "        `BaseTemplate`.\"\"\"\n",
    "        print('plugin')\n",
    "        \n",
    "        pass\n",
    "\n",
    "    def before_update(\n",
    "        self, strategy: Template, *args, **kwargs\n",
    "    ) -> CallbackResult:\n",
    "        \"\"\"Called before `optimizer.update()` by the `BaseTemplate`.\"\"\"\n",
    "        pass\n",
    "\n",
    "    def after_update(\n",
    "        self, strategy: Template, *args, **kwargs\n",
    "    ) -> CallbackResult:\n",
    "        \"\"\"Called after `optimizer.update()` by the `BaseTemplate`.\"\"\"\n",
    "        pass\n",
    "\n",
    "    def after_training_epoch(\n",
    "        self, strategy: Template, *args, **kwargs\n",
    "    ) -> CallbackResult:\n",
    "        \"\"\"Called after `train_epoch` by the `BaseTemplate`.\"\"\"\n",
    "        pass\n",
    "\n",
    "    def before_eval_iteration(\n",
    "        self, strategy: Template, *args, **kwargs\n",
    "    ) -> CallbackResult:\n",
    "        \"\"\"Called before the start of a training iteration by the\n",
    "        `BaseTemplate`.\"\"\"\n",
    "        pass\n",
    "\n",
    "    def before_eval_forward(\n",
    "        self, strategy: Template, *args, **kwargs\n",
    "    ) -> CallbackResult:\n",
    "        \"\"\"Called before `model.forward()` by the `BaseTemplate`.\"\"\"\n",
    "        pass\n",
    "\n",
    "    def after_eval_forward(\n",
    "        self, strategy: Template, *args, **kwargs\n",
    "    ) -> CallbackResult:\n",
    "        \"\"\"Called after `model.forward()` by the `BaseTemplate`.\"\"\"\n",
    "        pass\n",
    "\n",
    "    def after_eval_iteration(\n",
    "        self, strategy: Template, *args, **kwargs\n",
    "    ) -> CallbackResult:\n",
    "        \"\"\"Called after the end of an iteration by the\n",
    "        `BaseTemplate`.\"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ih6YdsQ6BMxD",
    "outputId": "7f0201d3-1210-4927-d6d0-4ea74d562984"
   },
   "outputs": [],
   "source": [
    "# from avalanche.training.storage_policy import ParametricBuffer, RandomExemplarsSelectionStrategy\n",
    "# from avalanche.training.storage_policy import ParametricBuffer, RandomExemplarsSelectionStrategy\n",
    "# storage_p = ParametricBuffer(\n",
    "#     max_size=60000,\n",
    "#     groupby='class',\n",
    "#     selection_strategy=RandomExemplarsSelectionStrategy()\n",
    "#     # selection_strategy=RandomExemplarsSelectionStrategy()\n",
    "\n",
    "# )\n",
    "\n",
    "\n",
    "# print(f\"Max buffer size: {storage_p.max_size}, current size: {len(storage_p.buffer)}\")\n",
    "# for i in range(5):\n",
    "#     strategy_state = SimpleNamespace(experience=benchmark.train_stream[i])\n",
    "#     # print(len(benchmark.train_stream[i]))\n",
    "#     storage_p.update(strategy_state)\n",
    "#     print(f\"Max buffer size: {storage_p.max_size}, current size: {len(storage_p.buffer)}\")\n",
    "#     # print(f\"class targets: {storage_p.buffer.targets}\\n\")\n",
    "\n",
    "# storage_p = ParametricBuffer(\n",
    "#     max_size=60000,\n",
    "#     groupby='class',\n",
    "#     selection_strategy=RandomExemplarsSelectionStrategy()\n",
    "#     # selection_strategy=RandomExemplarsSelectionStrategy()\n",
    "\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterable, Sequence, Optional, Union, List\n",
    "from pkg_resources import parse_version\n",
    "\n",
    "import torch\n",
    "from torch.nn import Module, CrossEntropyLoss\n",
    "from torch.optim import Optimizer\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from avalanche.benchmarks import CLExperience, CLStream\n",
    "from avalanche.core import BaseSGDPlugin\n",
    "from avalanche.training.plugins import SupervisedPlugin, EvaluationPlugin\n",
    "from avalanche.training.plugins.clock import Clock\n",
    "from avalanche.training.plugins.evaluation import default_evaluator\n",
    "from avalanche.training.templates.base import BaseTemplate, ExpSequence\n",
    "from avalanche.models.utils import avalanche_model_adaptation\n",
    "from avalanche.benchmarks.utils.data_loader import TaskBalancedDataLoader, \\\n",
    "    collate_from_data_or_kwargs\n",
    "from avalanche.training.utils import trigger_plugins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {
    "id": "p97eBJ5VBMxD"
   },
   "outputs": [],
   "source": [
    "# class KNN_DINO1(BaseTemplate):\n",
    "#     \"\"\"Base SGD class for continual learning skeletons.\n",
    "\n",
    "#     **Training loop**\n",
    "#     The training loop is organized as follows::\n",
    "\n",
    "#         train\n",
    "#             train_exp  # for each experience\n",
    "\n",
    "#     **Evaluation loop**\n",
    "#     The evaluation loop is organized as follows::\n",
    "\n",
    "#         eval\n",
    "#             eval_exp  # for each experience\n",
    "\n",
    "#     \"\"\"\n",
    "\n",
    "#     PLUGIN_CLASS = BaseSGDPlugin\n",
    "\n",
    "#     def __init__(\n",
    "#         self,\n",
    "#         model: Module,\n",
    "# #         optimizer: Optimizer,\n",
    "# #         criterion=CrossEntropyLoss(),\n",
    "#         train_mb_size: int = 1,\n",
    "#         train_epochs: int = 1,\n",
    "#         eval_mb_size: Optional[int] = 1,\n",
    "#         device=\"cpu\",\n",
    "#         plugins: Optional[List[\"SupervisedPlugin\"]] = None,\n",
    "#         evaluator: EvaluationPlugin = default_evaluator(),\n",
    "#         eval_every=-1,\n",
    "#         peval_mode=\"epoch\",\n",
    "#         k: int = 5,\n",
    "#         T: float = 0.07\n",
    "#     ):\n",
    "#         \"\"\"Init.\n",
    "\n",
    "#         :param model: PyTorch model.\n",
    "#         :param optimizer: PyTorch optimizer.\n",
    "#         :param criterion: loss function.\n",
    "#         :param train_mb_size: mini-batch size for training.\n",
    "#         :param train_epochs: number of training epochs.\n",
    "#         :param eval_mb_size: mini-batch size for eval.\n",
    "#         :param evaluator: (optional) instance of EvaluationPlugin for logging\n",
    "#             and metric computations. None to remove logging.\n",
    "#         :param eval_every: the frequency of the calls to `eval` inside the\n",
    "#             training loop. -1 disables the evaluation. 0 means `eval` is called\n",
    "#             only at the end of the learning experience. Values >0 mean that\n",
    "#             `eval` is called every `eval_every` epochs and at the end of the\n",
    "#             learning experience.\n",
    "#         :param peval_mode: one of {'epoch', 'iteration'}. Decides whether the\n",
    "#             periodic evaluation during training should execute every\n",
    "#             `eval_every` epochs or iterations (Default='epoch').\n",
    "#         \"\"\"\n",
    "#         super().__init__(model=model, device=device, plugins=plugins)\n",
    "\n",
    "# #         self.optimizer: Optimizer = optimizer\n",
    "# #         \"\"\" PyTorch optimizer. \"\"\"\n",
    "\n",
    "# #         self._criterion = criterion\n",
    "# #         \"\"\" Criterion. \"\"\"\n",
    "\n",
    "#         self.train_epochs: int = train_epochs\n",
    "#         \"\"\" Number of training epochs. \"\"\"\n",
    "\n",
    "#         self.train_mb_size: int = train_mb_size\n",
    "#         \"\"\" Training mini-batch size. \"\"\"\n",
    "\n",
    "#         self.eval_mb_size: int = (\n",
    "#             train_mb_size if eval_mb_size is None else eval_mb_size\n",
    "#         )\n",
    "#         \"\"\" Eval mini-batch size. \"\"\"\n",
    "\n",
    "#         if evaluator is None:\n",
    "#             evaluator = EvaluationPlugin()\n",
    "#         self.plugins.append(evaluator)\n",
    "#         self.evaluator = evaluator\n",
    "#         \"\"\" EvaluationPlugin used for logging and metric computations. \"\"\"\n",
    "\n",
    "#         # Configure periodic evaluation.\n",
    "#         assert peval_mode in {\"experience\", \"epoch\", \"iteration\"}\n",
    "#         self.eval_every = eval_every\n",
    "# #         peval = PeriodicEval(eval_every, peval_mode)\n",
    "# #         self.plugins.append(peval)\n",
    "\n",
    "#         self.clock = Clock()\n",
    "#         \"\"\" Incremental counters for strategy events. \"\"\"\n",
    "#         # WARNING: Clock needs to be the last plugin, otherwise\n",
    "#         # counters will be wrong for plugins called after it.\n",
    "#         self.plugins.append(self.clock)\n",
    "\n",
    "#         ###################################################################\n",
    "#         # State variables. These are updated during the train/eval loops. #\n",
    "#         ###################################################################\n",
    "\n",
    "#         self.adapted_dataset = None\n",
    "#         \"\"\" Data used to train. It may be modified by plugins. Plugins can \n",
    "#         append data to it (e.g. for replay). \n",
    "\n",
    "#         .. note::\n",
    "\n",
    "#             This dataset may contain samples from different experiences. If you \n",
    "#             want the original data for the current experience  \n",
    "#             use :attr:`.BaseTemplate.experience`.\n",
    "#         \"\"\"\n",
    "\n",
    "#         self.dataloader = None\n",
    "#         self.mbatch = None\n",
    "#         self.mb_output = None\n",
    "#         self.loss = None\n",
    "#         self._stop_training = False\n",
    "#         self.k = k\n",
    "#         self.T = T\n",
    "#         self.train_features = None\n",
    "#         self.train_labels = None\n",
    "\n",
    "#     @torch.no_grad()\n",
    "#     def train(self,\n",
    "#               experiences: Union[CLExperience,\n",
    "#                                  ExpSequence],\n",
    "#               eval_streams: Optional[Sequence[Union[CLExperience,\n",
    "#                                                     ExpSequence]]] = None,\n",
    "#               **kwargs):\n",
    "\n",
    "# #         super().train(experiences, eval_streams, **kwargs)\n",
    "# #         return self.evaluator.get_last_metrics()\n",
    "#         self.model.eval()  # Feature extraction mode, so we set the model to eval\n",
    "#         with torch.no_grad():\n",
    "#             if not isinstance(experiences, Iterable):\n",
    "#                 experiences = [experiences]\n",
    "#             for experience in experiences:\n",
    "#                 self._before_training_exp(**kwargs)\n",
    "#                 self._train_exp(experience, **kwargs)\n",
    "    \n",
    "        \n",
    "\n",
    "#     @torch.no_grad()\n",
    "#     def eval(self, exp_list: Union[CLExperience, CLStream], **kwargs):\n",
    "#         \"\"\"\n",
    "#         Evaluate the current model on a series of experiences and\n",
    "#         returns the last recorded value for each metric.\n",
    "\n",
    "#         :param exp_list: CL experience information.\n",
    "#         :param kwargs: custom arguments.\n",
    "\n",
    "#         :return: dictionary containing last recorded value for\n",
    "#             each metric name\n",
    "#         \"\"\"\n",
    "#         super().eval(exp_list, **kwargs)\n",
    "#         return self.evaluator.get_last_metrics()\n",
    "\n",
    "# #     def _train_exp(\n",
    "# #         self, experience: CLExperience, eval_streams, **kwargs\n",
    "# #     ):\n",
    "# #         # Should be implemented in Observation Type\n",
    "# #         raise NotImplementedError()\n",
    "\n",
    "#     def _eval_exp(self, **kwargs):\n",
    "#         self.eval_epoch(**kwargs)\n",
    "\n",
    "#     def make_optimizer(self, **kwargs):\n",
    "#         \"\"\"Optimizer initialization.\"\"\"\n",
    "#         # Should be implemented in Observation Type\n",
    "#         pass\n",
    "\n",
    "#     def criterion(self):\n",
    "#         \"\"\"Compute loss function.\"\"\"\n",
    "#         pass\n",
    "\n",
    "#     def forward(self):\n",
    "#         \"\"\"Compute the model's output given the current mini-batch.\"\"\"\n",
    "# #         raise NotImplementedError()\n",
    "#         return self.model(x)\n",
    "\n",
    "#     def model_adaptation(self, model=None):\n",
    "#         \"\"\"Adapts the model to the current experience.\"\"\"\n",
    "#         pass\n",
    "\n",
    "#     def stop_training(self):\n",
    "#         \"\"\"Signals to stop training at the next iteration.\"\"\"\n",
    "#         self._stop_training = True\n",
    "\n",
    "#     def training_epoch(self, **kwargs):\n",
    "#         # Should be implemented in Update Type\n",
    "# #         raise NotADirectoryError()\n",
    "        \n",
    "#         print('training_epoch', self.dataloader)\n",
    "#         for self.mbatch in self.dataloader:\n",
    "#             self._unpack_minibatch()\n",
    "#             self._before_training_iteration(**kwargs)\n",
    "\n",
    "# #             self._before_forward(**kwargs)\n",
    "# #             self.mb_output = self.forward()\n",
    "#             pass\n",
    "#             self._after_training_iteration(**kwargs)\n",
    "\n",
    "#     def backward(self):\n",
    "#         \"\"\"Run the backward pass.\"\"\"\n",
    "#         pass\n",
    "\n",
    "#     def optimizer_step(self):\n",
    "#         \"\"\"Execute the optimizer step (weights update).\"\"\"\n",
    "#         pass\n",
    "\n",
    "#     def eval_epoch(self, **kwargs):\n",
    "#         \"\"\"Evaluation loop over the current `self.dataloader`.\"\"\"\n",
    "#         for self.mbatch in self.dataloader:\n",
    "#             inputs, labels = self.mbatch[0].to(self.device), self.mbatch[1]\n",
    "#             self._unpack_minibatch()\n",
    "#             self._before_eval_iteration(**kwargs)\n",
    "\n",
    "#             self._before_eval_forward(**kwargs)\n",
    "#             features = self.model(inputs) \n",
    "# #             self.mb_output = self.forward()\n",
    "#             predictions = self.knn_classifier(features, self.train_features, self.train_labels, k=self.k, T=self.T)\n",
    "#             self.mb_output = predictions  # Set the minibatch output to KNN predictions\n",
    "\n",
    "#             self._after_eval_forward(**kwargs)\n",
    "# #             self.loss = self.criterion()\n",
    "\n",
    "#             self._after_eval_iteration(**kwargs)\n",
    "    \n",
    "#     def knn_classifier(self, test_features, train_labels):\n",
    "#     # Assuming train_features are transposed and ready to be used for dot product similarity\n",
    "#         distances, indices = torch.cdist(test_features, self.train_features).topk(self.k, largest=False, sorted=True)\n",
    "#         retrieved_neighbors = train_labels[indices]  # Retrieve labels of the k-nearest neighbors\n",
    "\n",
    "#         # Voting or averaging can happen here depending on your approach, example with voting:\n",
    "#         predictions, _ = torch.mode(retrieved_neighbors, dim=1)\n",
    "#         print('prediction is', predictions)\n",
    "#         return predictions\n",
    "\n",
    "#     def check_model_and_optimizer(self):\n",
    "#         # Should be implemented in observation type\n",
    "#         pass\n",
    "\n",
    "#     def _before_training_exp(self, **kwargs):\n",
    "#         \"\"\"Setup to train on a single experience.\"\"\"\n",
    "#         # Data Adaptation (e.g. add new samples/data augmentation)\n",
    "#         print('Data Adaptation')\n",
    "#         self._before_train_dataset_adaptation(**kwargs)\n",
    "#         self.train_dataset_adaptation(**kwargs)\n",
    "#         self._after_train_dataset_adaptation(**kwargs)\n",
    "#         print('make_train_dataloader')\n",
    "#         self.make_train_dataloader(**kwargs)\n",
    "#         print('_before_training_exp', self.dataloader)\n",
    "\n",
    "#         # Model Adaptation (e.g. freeze/add new units)\n",
    "#         print('Model Adaptation')\n",
    "#         self.model = self.model_adaptation()\n",
    "#         # self.make_optimizer()\n",
    "#         print('check_model_and_optimizer')\n",
    "#         self.check_model_and_optimizer()\n",
    "\n",
    "#         super()._before_training_exp(**kwargs)\n",
    "    \n",
    "        \n",
    "#     def _train_exp(\n",
    "#         self, experience: CLExperience, eval_streams=None, **kwargs\n",
    "#     ):\n",
    "#         \"\"\"Training loop over a single Experience object.\n",
    "\n",
    "#         :param experience: CL experience information.\n",
    "#         :param eval_streams: list of streams for evaluation.\n",
    "#             If None: use the training experience for evaluation.\n",
    "#             Use [] if you do not want to evaluate during training.\n",
    "#         :param kwargs: custom arguments.\n",
    "#         \"\"\"\n",
    "#         if eval_streams is None:\n",
    "#             eval_streams = [experience]\n",
    "#         self.model.eval()  # Ensure the model is in evaluation mode\n",
    "# #         self.make_train_dataloader()\n",
    "#         with torch.no_grad():\n",
    "#             for i, exp in enumerate(eval_streams):\n",
    "#                 if not isinstance(exp, Iterable):\n",
    "#                     eval_streams[i] = [exp]\n",
    "#             for _ in range(self.train_epochs):\n",
    "#                 self._before_training_epoch(**kwargs)\n",
    "# #                 print(self.dataloader)\n",
    "\n",
    "#                 if self._stop_training:  # Early stopping\n",
    "#                     self._stop_training = False\n",
    "#                     break\n",
    "\n",
    "#                 self.training_epoch(**kwargs)\n",
    "#                 self._after_training_epoch(**kwargs)\n",
    "\n",
    "#     def _save_train_state(self):\n",
    "#         \"\"\"Save the training state which may be modified by the eval loop.\n",
    "\n",
    "#         This currently includes: experience, adapted_dataset, dataloader,\n",
    "#         is_training, and train/eval modes for each module.\n",
    "\n",
    "#         TODO: we probably need a better way to do this.\n",
    "#         \"\"\"\n",
    "#         state = super()._save_train_state()\n",
    "#         new_state = {\n",
    "#             \"adapted_dataset\": self.adapted_dataset,\n",
    "#             \"dataloader\": self.dataloader,\n",
    "#         }\n",
    "#         return {**state, **new_state}\n",
    "    \n",
    "#     def _before_train_dataset_adaptation(self, **kwargs):\n",
    "#         pass\n",
    "#     def train_dataset_adaptation(self, **kwargs):\n",
    "#         \"\"\"Initialize `self.adapted_dataset`.\"\"\"\n",
    "#         self.adapted_dataset = self.experience.dataset\n",
    "#         self.adapted_dataset = self.adapted_dataset.train()\n",
    "\n",
    "#     def _load_train_state(self, prev_state):\n",
    "#         super()._load_train_state(prev_state)\n",
    "#         self.adapted_dataset = prev_state[\"adapted_dataset\"]\n",
    "#         self.dataloader = prev_state[\"dataloader\"]\n",
    "\n",
    "#     def _before_eval_exp(self, **kwargs):\n",
    "\n",
    "#         # Data Adaptation\n",
    "#         self._before_eval_dataset_adaptation(**kwargs)\n",
    "#         self.eval_dataset_adaptation(**kwargs)\n",
    "#         self._after_eval_dataset_adaptation(**kwargs)\n",
    "\n",
    "#         self.make_eval_dataloader(**kwargs)\n",
    "#         # Model Adaptation (e.g. freeze/add new units)\n",
    "#         self.model = self.model_adaptation()\n",
    "\n",
    "#         super()._before_eval_exp(**kwargs)\n",
    "\n",
    "#     def make_train_dataloader(\n",
    "#         self,\n",
    "#         num_workers=0,\n",
    "#         shuffle=True,\n",
    "#         pin_memory=True,\n",
    "#         persistent_workers=False,\n",
    "#         **kwargs\n",
    "#     ):\n",
    "#         \"\"\"Data loader initialization.\n",
    "\n",
    "#         Called at the start of each learning experience after the dataset\n",
    "#         adaptation.\n",
    "\n",
    "#         :param num_workers: number of thread workers for the data loading.\n",
    "#         :param shuffle: True if the data should be shuffled, False otherwise.\n",
    "#         :param pin_memory: If True, the data loader will copy Tensors into CUDA\n",
    "#             pinned memory before returning them. Defaults to True.\n",
    "#         \"\"\"\n",
    "\n",
    "#         other_dataloader_args = {}\n",
    "\n",
    "#         if parse_version(torch.__version__) >= parse_version(\"1.7.0\"):\n",
    "#             other_dataloader_args[\"persistent_workers\"] = persistent_workers\n",
    "#         for k, v in kwargs.items():\n",
    "#             other_dataloader_args[k] = v\n",
    "\n",
    "#         self.dataloader = TaskBalancedDataLoader(\n",
    "#             self.adapted_dataset,\n",
    "#             oversample_small_groups=True,\n",
    "#             num_workers=num_workers,\n",
    "#             batch_size=self.train_mb_size,\n",
    "#             shuffle=shuffle,\n",
    "#             pin_memory=pin_memory,\n",
    "#             **other_dataloader_args\n",
    "#         )\n",
    "\n",
    "#     def make_eval_dataloader(\n",
    "#         self, num_workers=0, pin_memory=True, persistent_workers=False, **kwargs\n",
    "#     ):\n",
    "#         \"\"\"\n",
    "#         Initializes the eval data loader.\n",
    "#         :param num_workers: How many subprocesses to use for data loading.\n",
    "#             0 means that the data will be loaded in the main process.\n",
    "#             (default: 0).\n",
    "#         :param pin_memory: If True, the data loader will copy Tensors into CUDA\n",
    "#             pinned memory before returning them. Defaults to True.\n",
    "#         :param kwargs:\n",
    "#         :return:\n",
    "#         \"\"\"\n",
    "#         other_dataloader_args = {}\n",
    "\n",
    "#         if parse_version(torch.__version__) >= parse_version(\"1.7.0\"):\n",
    "#             other_dataloader_args[\"persistent_workers\"] = persistent_workers\n",
    "#         for k, v in kwargs.items():\n",
    "#             other_dataloader_args[k] = v\n",
    "\n",
    "#         collate_from_data_or_kwargs(self.adapted_dataset,\n",
    "#                                     other_dataloader_args)\n",
    "#         self.dataloader = DataLoader(\n",
    "#             self.adapted_dataset,\n",
    "#             num_workers=num_workers,\n",
    "#             batch_size=self.eval_mb_size,\n",
    "#             pin_memory=pin_memory,\n",
    "#             **other_dataloader_args\n",
    "#         )\n",
    "\n",
    "#     def eval_dataset_adaptation(self, **kwargs):\n",
    "#         \"\"\"Initialize `self.adapted_dataset`.\"\"\"\n",
    "#         self.adapted_dataset = self.experience.dataset\n",
    "#         self.adapted_dataset = self.adapted_dataset.eval()\n",
    "\n",
    "#     def _unpack_minibatch(self):\n",
    "#         \"\"\"Move to device\"\"\"\n",
    "#         # First verify the mini-batch\n",
    "#         self._check_minibatch()\n",
    "\n",
    "#         if isinstance(self.mbatch, tuple):\n",
    "#             self.mbatch = list(self.mbatch)\n",
    "#         for i in range(len(self.mbatch)):\n",
    "#             self.mbatch[i] = self.mbatch[i].to(self.device)\n",
    "\n",
    "#     #########################################################\n",
    "#     # Plugin Triggers                                       #\n",
    "#     #########################################################\n",
    "\n",
    "#     def _before_training_epoch(self, **kwargs):\n",
    "#         trigger_plugins(self, \"before_training_epoch\", **kwargs)\n",
    "\n",
    "#     def _after_training_epoch(self, **kwargs):\n",
    "#         trigger_plugins(self, \"after_training_epoch\", **kwargs)\n",
    "\n",
    "#     def _before_training_iteration(self, **kwargs):\n",
    "#         trigger_plugins(self, \"before_training_iteration\", **kwargs)\n",
    "\n",
    "#     def _before_forward(self, **kwargs):\n",
    "#         trigger_plugins(self, \"before_forward\", **kwargs)\n",
    "\n",
    "#     def _after_forward(self, **kwargs):\n",
    "#         trigger_plugins(self, \"after_forward\", **kwargs)\n",
    "\n",
    "#     def _before_backward(self, **kwargs):\n",
    "#         trigger_plugins(self, \"before_backward\", **kwargs)\n",
    "\n",
    "#     def _after_backward(self, **kwargs):\n",
    "#         trigger_plugins(self, \"after_backward\", **kwargs)\n",
    "\n",
    "#     def _after_training_iteration(self, **kwargs):\n",
    "#         trigger_plugins(self, \"after_training_iteration\", **kwargs)\n",
    "\n",
    "#     def _before_update(self, **kwargs):\n",
    "#         trigger_plugins(self, \"before_update\", **kwargs)\n",
    "\n",
    "#     def _after_update(self, **kwargs):\n",
    "#         trigger_plugins(self, \"after_update\", **kwargs)\n",
    "\n",
    "#     def _before_eval_iteration(self, **kwargs):\n",
    "#         trigger_plugins(self, \"before_eval_iteration\", **kwargs)\n",
    "\n",
    "#     def _before_eval_forward(self, **kwargs):\n",
    "#         trigger_plugins(self, \"before_eval_forward\", **kwargs)\n",
    "\n",
    "#     def _after_eval_forward(self, **kwargs):\n",
    "#         trigger_plugins(self, \"after_eval_forward\", **kwargs)\n",
    "\n",
    "#     def _after_eval_iteration(self, **kwargs):\n",
    "#         trigger_plugins(self, \"after_eval_iteration\", **kwargs)\n",
    "\n",
    "#     # ==================================================================> NEW\n",
    "\n",
    "#     def _before_train_dataset_adaptation(self, **kwargs):\n",
    "#         trigger_plugins(self, \"before_train_dataset_adaptation\", **kwargs)\n",
    "\n",
    "#     def _after_train_dataset_adaptation(self, **kwargs):\n",
    "#         trigger_plugins(self, \"after_train_dataset_adaptation\", **kwargs)\n",
    "\n",
    "#     def _before_eval_dataset_adaptation(self, **kwargs):\n",
    "#         trigger_plugins(self, \"before_eval_dataset_adaptation\", **kwargs)\n",
    "\n",
    "#     def _after_eval_dataset_adaptation(self, **kwargs):\n",
    "#         trigger_plugins(self, \"after_eval_dataset_adaptation\", **kwargs)\n",
    "# # "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN_storagePlugin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 904,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics import Accuracy  # Using torchmetrics for simplicity\n",
    "# from avalanche.evaluation.metrics import Accuracy\n",
    "\n",
    "from torchmetrics import Accuracy\n",
    "\n",
    "class AccuracyMetric:\n",
    "    def __init__(self, task='multiclass'):\n",
    "        # Initialize the metric for multiclass classification by default\n",
    "        self.metric = Accuracy(num_classes=None, average='macro', task=task)\n",
    "\n",
    "    def update(self, preds, targets):\n",
    "        preds, targets = preds.detach(), targets.detach()\n",
    "        self.metric.update(preds, targets)\n",
    "\n",
    "    def result(self):\n",
    "        return self.metric.compute()\n",
    "\n",
    "    def reset(self):\n",
    "        self.metric.reset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 908,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class KNN_storagePlugin(SupervisedPlugin):\n",
    "    \"\"\"\n",
    "    Experience replay plugin.\n",
    "\n",
    "    Handles an external memory filled with randomly selected\n",
    "    patterns and implementing `before_training_exp` and `after_training_exp`\n",
    "    callbacks.\n",
    "    The `before_training_exp` callback is implemented in order to use the\n",
    "    dataloader that creates mini-batches with examples from both training\n",
    "    data and external memory. The examples in the mini-batch is balanced\n",
    "    such that there are the same number of examples for each experience.\n",
    "\n",
    "    The `after_training_exp` callback is implemented in order to add new\n",
    "    patterns to the external memory.\n",
    "\n",
    "    The :mem_size: attribute controls the total number of patterns to be stored\n",
    "    in the external memory.\n",
    "\n",
    "    :param batch_size: the size of the data batch. If set to `None`, it\n",
    "        will be set equal to the strategy's batch size.\n",
    "    :param batch_size_mem: the size of the memory batch. If\n",
    "        `task_balanced_dataloader` is set to True, it must be greater than or\n",
    "        equal to the number of tasks. If its value is set to `None`\n",
    "        (the default value), it will be automatically set equal to the\n",
    "        data batch size.\n",
    "    :param task_balanced_dataloader: if True, buffer data loaders will be\n",
    "            task-balanced, otherwise it will create a single dataloader for the\n",
    "            buffer samples.\n",
    "    :param storage_policy: The policy that controls how to add new exemplars\n",
    "                           in memory\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        mem_size: int = 200,\n",
    "        batch_size: int = None,\n",
    "        batch_size_mem: int = None,\n",
    "        task_balanced_dataloader: bool = False,\n",
    "        storage_policy: Optional[\"ExemplarsBuffer\"] = None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.mem_size = mem_size\n",
    "        self.batch_size = batch_size\n",
    "        self.batch_size_mem = batch_size_mem\n",
    "        self.task_balanced_dataloader = task_balanced_dataloader\n",
    "\n",
    "        if storage_policy is not None:  # Use other storage policy\n",
    "            self.storage_policy = storage_policy\n",
    "            assert storage_policy.max_size == self.mem_size\n",
    "        else:  # Default\n",
    "            self.storage_policy = ExperienceBalancedBuffer(\n",
    "                max_size=self.mem_size, adaptive_size=True\n",
    "            )\n",
    "        self.accuracy_metric = AccuracyMetric(task='multiclass')\n",
    "\n",
    "    @property\n",
    "    def ext_mem(self):\n",
    "        return self.storage_policy.buffer_groups  # a Dict<task_id, Dataset>\n",
    "\n",
    "    def before_training_exp(\n",
    "        self,\n",
    "        strategy: \"SupervisedTemplate\",\n",
    "        num_workers: int = 0,\n",
    "        shuffle: bool = True,\n",
    "        **kwargs\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Dataloader to build batches containing examples from both memories and\n",
    "        the training dataset\n",
    "        \"\"\"\n",
    "        if len(self.storage_policy.buffer) == 0:\n",
    "            # first experience. We don't use the buffer, no need to change\n",
    "            # the dataloader.\n",
    "            buffer_size = len(self.storage_policy.buffer)\n",
    "            print(\"buffer size: \" + str(buffer_size))\n",
    "            return\n",
    "\n",
    "        batch_size = self.batch_size\n",
    "        if batch_size is None:\n",
    "            batch_size = strategy.train_mb_size\n",
    "\n",
    "        batch_size_mem = self.batch_size_mem\n",
    "        if batch_size_mem is None:\n",
    "            batch_size_mem = strategy.train_mb_size\n",
    "\n",
    "        strategy.dataloader = ReplayDataLoader(\n",
    "            strategy.adapted_dataset,\n",
    "            self.storage_policy.buffer,\n",
    "            oversample_small_tasks=True,\n",
    "            batch_size=batch_size,\n",
    "            batch_size_mem=batch_size_mem,\n",
    "            task_balanced_dataloader=self.task_balanced_dataloader,\n",
    "            num_workers=num_workers,\n",
    "            shuffle=shuffle,\n",
    "        )\n",
    "        buffer_size = len(self.storage_policy.buffer)\n",
    "        print(\"buffer size: \" + str(buffer_size))\n",
    "\n",
    "    def after_training_exp(self, strategy: \"SupervisedTemplate\", **kwargs):\n",
    "        self.storage_policy.update(strategy, **kwargs)\n",
    "        buffer_size = len(self.storage_policy.buffer)\n",
    "        print(\"after training exp buffer size: \" + str(buffer_size))\n",
    "    def after_eval_iteration(self, strategy: \"SupervisedTemplate\", **kwargs):\n",
    "        \"\"\"\n",
    "        Calculate and log the accuracy after each evaluation iteration.\n",
    "        \"\"\"\n",
    "        # Access the predictions and true labels\n",
    "        predictions = strategy.mb_output\n",
    "        true_labels = strategy.mb_y\n",
    "\n",
    "        # Update the accuracy metric\n",
    "        self.accuracy_metric.update(predictions, true_labels)\n",
    "\n",
    "        # Log the current accuracy\n",
    "        current_accuracy = self.accuracy_metric.result()\n",
    "        print(f\"Current accuracy: {current_accuracy * 100:.2f}%\")\n",
    "        self.accuracy_metric.reset()  # Reset for next iteration or experience\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN_DINO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 909,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class KNN_DINO1(BaseTemplate):\n",
    "    \"\"\"Base SGD class for continual learning skeletons.\n",
    "\n",
    "    **Training loop**\n",
    "    The training loop is organized as follows::\n",
    "\n",
    "        train\n",
    "            train_exp  # for each experience\n",
    "\n",
    "    **Evaluation loop**\n",
    "    The evaluation loop is organized as follows::\n",
    "\n",
    "        eval\n",
    "            eval_exp  # for each experience\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    PLUGIN_CLASS = BaseSGDPlugin\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        model: Module,\n",
    "#         optimizer: Optimizer,\n",
    "#         criterion=CrossEntropyLoss(),\n",
    "        train_mb_size: int = 1,\n",
    "        train_epochs: int = 1,\n",
    "        eval_mb_size: Optional[int] = 1,\n",
    "        device=\"cpu\",\n",
    "        plugins: Optional[List[\"SupervisedPlugin\"]] = None,\n",
    "        evaluator: EvaluationPlugin = default_evaluator(),\n",
    "        eval_every=-1,\n",
    "        peval_mode=\"epoch\",\n",
    "        k: int = 5,\n",
    "        T: float = 0.07\n",
    "    ):\n",
    "        \"\"\"Init.\n",
    "\n",
    "        :param model: PyTorch model.\n",
    "        :param optimizer: PyTorch optimizer.\n",
    "        :param criterion: loss function.\n",
    "        :param train_mb_size: mini-batch size for training.\n",
    "        :param train_epochs: number of training epochs.\n",
    "        :param eval_mb_size: mini-batch size for eval.\n",
    "        :param evaluator: (optional) instance of EvaluationPlugin for logging\n",
    "            and metric computations. None to remove logging.\n",
    "        :param eval_every: the frequency of the calls to `eval` inside the\n",
    "            training loop. -1 disables the evaluation. 0 means `eval` is called\n",
    "            only at the end of the learning experience. Values >0 mean that\n",
    "            `eval` is called every `eval_every` epochs and at the end of the\n",
    "            learning experience.\n",
    "        :param peval_mode: one of {'epoch', 'iteration'}. Decides whether the\n",
    "            periodic evaluation during training should execute every\n",
    "            `eval_every` epochs or iterations (Default='epoch').\n",
    "        \"\"\"\n",
    "        super().__init__(model=model, device=device, plugins=plugins)\n",
    "\n",
    "#         self.optimizer: Optimizer = optimizer\n",
    "#         \"\"\" PyTorch optimizer. \"\"\"\n",
    "\n",
    "#         self._criterion = criterion\n",
    "#         \"\"\" Criterion. \"\"\"\n",
    "\n",
    "        self.train_epochs: int = train_epochs\n",
    "        \"\"\" Number of training epochs. \"\"\"\n",
    "\n",
    "        self.train_mb_size: int = train_mb_size\n",
    "        \"\"\" Training mini-batch size. \"\"\"\n",
    "\n",
    "        self.eval_mb_size: int = (\n",
    "            train_mb_size if eval_mb_size is None else eval_mb_size\n",
    "        )\n",
    "        \"\"\" Eval mini-batch size. \"\"\"\n",
    "\n",
    "        if evaluator is None:\n",
    "            evaluator = EvaluationPlugin()\n",
    "        self.plugins.append(evaluator)\n",
    "        self.evaluator = evaluator\n",
    "        assert peval_mode in {\"experience\", \"epoch\", \"iteration\"}\n",
    "        self.eval_every = eval_every\n",
    "#         peval = PeriodicEval(eval_every, peval_mode)\n",
    "#         self.plugins.append(peval)\n",
    "\n",
    "        self.clock = Clock()\n",
    "        \"\"\" Incremental counters for strategy events. \"\"\"\n",
    "        self.plugins.append(self.clock)\n",
    "\n",
    "        self.adapted_dataset = None\n",
    "        \"\"\" Data used to train. It may be modified by plugins. Plugins can \n",
    "        append data to it (e.g. for replay). \n",
    "\n",
    "        .. note::\n",
    "\n",
    "            This dataset may contain samples from different experiences. If you \n",
    "            want the original data for the current experience  \n",
    "            use :attr:`.BaseTemplate.experience`.\n",
    "        \"\"\"\n",
    "        self.model = model\n",
    "        self.dataloader = None\n",
    "        self.mbatch = None\n",
    "        self.mb_output = None\n",
    "        self.loss = None\n",
    "        self._stop_training = False\n",
    "        self.k = k\n",
    "        self.T = T\n",
    "        self.train_features = None\n",
    "        self.train_labels = None\n",
    "        self.replay_plugin = plugins[0]\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def train(self,\n",
    "              experiences: Union[CLExperience,\n",
    "                                 ExpSequence],\n",
    "              eval_streams: Optional[Sequence[Union[CLExperience,\n",
    "                                                    ExpSequence]]] = None,\n",
    "              **kwargs):\n",
    "\n",
    "#         super().train(experiences, eval_streams, **kwargs)\n",
    "#         return self.evaluator.get_last_metrics()\n",
    "        self.is_training = True\n",
    "        self._stop_training = False\n",
    "\n",
    "        self.model.eval()  # Feature extraction mode, so we set the model to eval\n",
    "        self.model.to(self.device)\n",
    "        with torch.no_grad():\n",
    "            if not isinstance(experiences, Iterable):\n",
    "                experiences = [experiences]\n",
    "            if eval_streams is None:\n",
    "                eval_streams = [experiences]\n",
    "            self._eval_streams = _group_experiences_by_stream(eval_streams)\n",
    "\n",
    "            self._before_training(**kwargs)\n",
    "            \n",
    "            for self.experience in experiences:\n",
    "                self._before_training_exp(**kwargs)\n",
    "                self._train_exp(experience, **kwargs)\n",
    "                self._after_training_exp(**kwargs)\n",
    "            self._after_training(**kwargs)\n",
    "                \n",
    "                \n",
    "                \n",
    "    def forward(self):\n",
    "        \"\"\"Compute the model's output given the current mini-batch.\"\"\"\n",
    "#         raise NotImplementedError()\n",
    "        if self.mb_x is not None:\n",
    "            return self.model(self.mb_x.to(self.device))  # Ensure device compatibility\n",
    "        else:\n",
    "            raise ValueError(\"Input data not loaded: self.mb_x is None\")\n",
    "\n",
    "    def _before_training_exp(self, **kwargs):\n",
    "        \"\"\"Setup to train on a single experience.\"\"\"\n",
    "        # Data Adaptation (e.g. add new samples/data augmentation)\n",
    "        self._before_train_dataset_adaptation(**kwargs)\n",
    "        self.train_dataset_adaptation(**kwargs)\n",
    "        self._after_train_dataset_adaptation(**kwargs)\n",
    "#         trigger_plugins(self, \"before_training_exp\", **kwargs)\n",
    "        self.make_train_dataloader(**kwargs)\n",
    "        print(self.dataloader)\n",
    "\n",
    "        # Model Adaptation (e.g. freeze/add new units)\n",
    "#         self.model = self.model_adaptation()\n",
    "        # self.make_optimizer()\n",
    "        self.check_model_and_optimizer()\n",
    "\n",
    "        super()._before_training_exp(**kwargs)\n",
    "#         if self.dataloader is None:\n",
    "#         # If not set, initialize it here\n",
    "#             self.make_train_dataloader()\n",
    "#             print('train dataloader is made')\n",
    "\n",
    "#         if self.dataloader is None or len(self.dataloader) == 0:\n",
    "#             raise ValueError(\"Dataloader is not initialized or contains no data.\")\n",
    "    def _before_train_dataset_adaptation(self, **kwargs):\n",
    "        trigger_plugins(self, \"before_train_dataset_adaptation\", **kwargs)\n",
    "\n",
    "    def _after_train_dataset_adaptation(self, **kwargs):\n",
    "        trigger_plugins(self, \"after_train_dataset_adaptation\", **kwargs)\n",
    "\n",
    "    def train_dataset_adaptation(self, **kwargs):\n",
    "        \"\"\"Initialize `self.adapted_dataset`.\"\"\"\n",
    "        self.adapted_dataset = self.experience.dataset\n",
    "        self.adapted_dataset = self.adapted_dataset.train()\n",
    "        print(len(self.adapted_dataset))\n",
    "    def make_train_dataloader(\n",
    "        self,\n",
    "        num_workers=0,\n",
    "        shuffle=True,\n",
    "        pin_memory=True,\n",
    "        persistent_workers=False,\n",
    "        **kwargs\n",
    "    ):\n",
    "        \"\"\"Data loader initialization.\n",
    "\n",
    "        Called at the start of each learning experience after the dataset\n",
    "        adaptation.\n",
    "\n",
    "        :param num_workers: number of thread workers for the data loading.\n",
    "        :param shuffle: True if the data should be shuffled, False otherwise.\n",
    "        :param pin_memory: If True, the data loader will copy Tensors into CUDA\n",
    "            pinned memory before returning them. Defaults to True.\n",
    "        \"\"\"\n",
    "\n",
    "        other_dataloader_args = {}\n",
    "\n",
    "        if parse_version(torch.__version__) >= parse_version(\"1.7.0\"):\n",
    "            other_dataloader_args[\"persistent_workers\"] = persistent_workers\n",
    "        for k, v in kwargs.items():\n",
    "            other_dataloader_args[k] = v\n",
    "\n",
    "        self.dataloader = TaskBalancedDataLoader(\n",
    "            self.adapted_dataset,\n",
    "            oversample_small_groups=True,\n",
    "            num_workers=num_workers,\n",
    "            batch_size=self.train_mb_size,\n",
    "            shuffle=shuffle,\n",
    "            pin_memory=pin_memory,\n",
    "            **other_dataloader_args\n",
    "        )\n",
    "    def model_adaptation(self, model=None):\n",
    "        \"\"\"Adapts the model to the current experience.\"\"\"\n",
    "        pass\n",
    "    def check_model_and_optimizer(self):\n",
    "        # Should be implemented in observation type\n",
    "        pass\n",
    "    def _train_exp(\n",
    "        self, experience: CLExperience, eval_streams=None, **kwargs\n",
    "    ):\n",
    "        \"\"\"Training loop over a single Experience object.\n",
    "\n",
    "        :param experience: CL experience information.\n",
    "        :param eval_streams: list of streams for evaluation.\n",
    "            If None: use the training experience for evaluation.\n",
    "            Use [] if you do not want to evaluate during training.\n",
    "        :param kwargs: custom arguments.\n",
    "        \"\"\"\n",
    "        if eval_streams is None:\n",
    "            eval_streams = [experience]\n",
    "        self.model.eval()  # Ensure the model is in evaluation mode\n",
    "        with torch.no_grad():\n",
    "            for i, exp in enumerate(eval_streams):\n",
    "                if not isinstance(exp, Iterable):\n",
    "                    eval_streams[i] = [exp]\n",
    "            for _ in range(self.train_epochs):\n",
    "                self._before_training_epoch(**kwargs)\n",
    "\n",
    "                if self._stop_training:  # Early stopping\n",
    "                    self._stop_training = False\n",
    "                    break\n",
    "\n",
    "                self.training_epoch(**kwargs)\n",
    "                self._after_training_epoch(**kwargs)\n",
    "    def _before_training_epoch(self, **kwargs):\n",
    "        print('_before_training_epoch')\n",
    "        trigger_plugins(self, \"before_training_epoch\", **kwargs)\n",
    "    \n",
    "    def training_epoch(self, **kwargs):\n",
    "        # Should be implemented in Update Type\n",
    "#         raise NotADirectoryError()\n",
    "        print('training_epoch')\n",
    "        print(self.dataloader)\n",
    "#         print(self.model) \n",
    "        \n",
    "        for self.mbatch in self.dataloader:\n",
    "            self._unpack_minibatch()\n",
    "            self._before_training_iteration(**kwargs)\n",
    "\n",
    "# #             self._before_forward(**kwargs)\n",
    "# #             self.mb_output = self.forward()\n",
    "#             with torch.no_grad():\n",
    "#                 features = self.forward()\n",
    "#                 all_features.append(features)\n",
    "#                 all_labels.append(self.mb_y)\n",
    "#                 self.mb_output = self.knn_classifier(test_features=features,\n",
    "#                                                  train_features=self.train_features,\n",
    "#                                                  train_labels=self.train_labels,\n",
    "#                                                  k=self.k, T=self.T)\n",
    "            self._after_training_iteration(**kwargs)\n",
    "\n",
    "    def _unpack_minibatch(self):\n",
    "        \"\"\"Move to device\"\"\"\n",
    "#         print('_unpack_minibatch')\n",
    "        # First verify the mini-batch\n",
    "#         self._check_minibatch()\n",
    "\n",
    "        if isinstance(self.mbatch, tuple):\n",
    "            self.mbatch = list(self.mbatch)\n",
    "        for i in range(len(self.mbatch)):\n",
    "#             print(i)\n",
    "            self.mbatch[i] = self.mbatch[i].to(self.device)\n",
    "        self.mb_x, self.mb_y, _ = self.mbatch\n",
    "    def _before_training_iteration(self, **kwargs):\n",
    "#         print('_before_training_iteration')\n",
    "        trigger_plugins(self, \"before_training_iteration\", **kwargs)\n",
    "        \n",
    "    def _after_training_iteration(self, **kwargs):\n",
    "#         print('_after_training_iteration')\n",
    "#         trigger_plugins(self, \"after_training_iteration\", **kwargs)\n",
    "        pass\n",
    "    def _after_training_epoch(self, **kwargs):\n",
    "#         trigger_plugins(self, \"after_training_epoch\", **kwargs)\n",
    "        print('_after_training_epoch')\n",
    "        pass\n",
    "    \n",
    "#     ---------------------- eval ------------------------------------\n",
    "    @torch.no_grad()\n",
    "    def eval(\n",
    "        self,\n",
    "        exp_list: Union[CLExperience, CLStream],\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Evaluate the current model on a series of experiences and\n",
    "        returns the last recorded value for each metric.\n",
    "\n",
    "        :param exp_list: CL experience information.\n",
    "        :param kwargs: custom arguments.\n",
    "\n",
    "        :return: dictionary containing last recorded value for\n",
    "            each metric name\n",
    "        \"\"\"\n",
    "        # eval can be called inside the train method.\n",
    "        # Save the shared state here to restore before returning.\n",
    "        self.model.to(self.device)\n",
    "#         print('eval')\n",
    "#         print(self.model)\n",
    "        prev_train_state = self._save_train_state()\n",
    "        self.is_training = False\n",
    "        self.model.eval()\n",
    "\n",
    "        if not isinstance(exp_list, Iterable):\n",
    "            exp_list = [exp_list]\n",
    "        self.current_eval_stream = exp_list\n",
    "\n",
    "        self._before_eval(**kwargs)\n",
    "        for self.experience in exp_list:\n",
    "            self._before_eval_exp(**kwargs)\n",
    "            self._eval_exp(**kwargs)\n",
    "            self._after_eval_exp(**kwargs)\n",
    "\n",
    "        self._after_eval(**kwargs)\n",
    "\n",
    "        # restore previous shared state.\n",
    "        self._load_train_state(prev_train_state)\n",
    "    \n",
    "    def backward(self):\n",
    "        \"\"\"Run the backward pass.\"\"\"\n",
    "        pass\n",
    "\n",
    "    def optimizer_step(self):\n",
    "        \"\"\"Execute the optimizer step (weights update).\"\"\"\n",
    "        pass\n",
    "    \n",
    "    def criterion(self):\n",
    "        \"\"\"Compute loss function.\"\"\"\n",
    "        pass\n",
    "    \n",
    "    def _before_eval_exp(self, **kwargs):\n",
    "\n",
    "        # Data Adaptation\n",
    "#         print(self.model)\n",
    "        self._before_eval_dataset_adaptation(**kwargs)\n",
    "        self.eval_dataset_adaptation(**kwargs)\n",
    "        self._after_eval_dataset_adaptation(**kwargs)\n",
    "\n",
    "        self.make_eval_dataloader(**kwargs)\n",
    "        # Model Adaptation (e.g. freeze/add new units)\n",
    "        print('eval Model Adaptation ')\n",
    "#         self.model = self.model_adaptation(self.model)\n",
    "#         print(self.model)\n",
    "\n",
    "        super()._before_eval_exp(**kwargs)\n",
    "        \n",
    "    def _before_eval_dataset_adaptation(self, **kwargs):\n",
    "        trigger_plugins(self, \"before_eval_dataset_adaptation\", **kwargs)\n",
    "\n",
    "    def _after_eval_dataset_adaptation(self, **kwargs):\n",
    "        trigger_plugins(self, \"after_eval_dataset_adaptation\", **kwargs)\n",
    "    \n",
    "    def eval_dataset_adaptation(self, **kwargs):\n",
    "        \"\"\"Initialize `self.adapted_dataset`.\"\"\"\n",
    "        print('eval_dataset_adaptation')\n",
    "        self.adapted_dataset = self.experience.dataset\n",
    "        self.adapted_dataset = self.adapted_dataset.eval()\n",
    "        print(len(self.adapted_dataset))\n",
    "\n",
    "    def make_eval_dataloader(\n",
    "        self, num_workers=0, pin_memory=True, persistent_workers=False, **kwargs\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initializes the eval data loader.\n",
    "        :param num_workers: How many subprocesses to use for data loading.\n",
    "            0 means that the data will be loaded in the main process.\n",
    "            (default: 0).\n",
    "        :param pin_memory: If True, the data loader will copy Tensors into CUDA\n",
    "            pinned memory before returning them. Defaults to True.\n",
    "        :param kwargs:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        other_dataloader_args = {}\n",
    "\n",
    "        if parse_version(torch.__version__) >= parse_version(\"1.7.0\"):\n",
    "            other_dataloader_args[\"persistent_workers\"] = persistent_workers\n",
    "        for k, v in kwargs.items():\n",
    "            other_dataloader_args[k] = v\n",
    "\n",
    "        collate_from_data_or_kwargs(self.adapted_dataset,\n",
    "                                    other_dataloader_args)\n",
    "        self.dataloader = DataLoader(\n",
    "            self.adapted_dataset,\n",
    "            num_workers=num_workers,\n",
    "            batch_size=self.eval_mb_size,\n",
    "            pin_memory=pin_memory,\n",
    "            **other_dataloader_args\n",
    "        )\n",
    "        \n",
    "    def _eval_exp(self, **kwargs):\n",
    "        self.eval_epoch(**kwargs)\n",
    "    \n",
    "    def eval_epoch(self, **kwargs):\n",
    "        \"\"\"Evaluation loop over the current `self.dataloader`.\"\"\"\n",
    "#         print('len(self.dataloader)', len(self.dataloader))\n",
    "\n",
    "        for self.mbatch in self.dataloader:\n",
    "            inputs, labels = self.mbatch[0].to(self.device), self.mbatch[1]\n",
    "            self._unpack_minibatch()\n",
    "            self._before_eval_iteration(**kwargs)\n",
    "\n",
    "            self._before_eval_forward(**kwargs)\n",
    "            features = self.forward()\n",
    "#             print(features)\n",
    "#             print(self.buffer)\n",
    "#             features = self.model(self.mb_x)\n",
    "            \n",
    "#             print(self.model)\n",
    "#             self.mb_output = self.forward()\n",
    "            predictions = self.knn_classifier(features)\n",
    "            self.mb_output = predictions  # Set the minibatch output to KNN predictions\n",
    "\n",
    "            self._after_eval_forward(**kwargs)\n",
    "#             self.loss = self.criterion()\n",
    "\n",
    "            self._after_eval_iteration(**kwargs)\n",
    "    def _before_eval_iteration(self, **kwargs):\n",
    "        trigger_plugins(self, \"before_eval_iteration\", **kwargs)\n",
    "\n",
    "    def _before_eval_forward(self, **kwargs):\n",
    "        trigger_plugins(self, \"before_eval_forward\", **kwargs)\n",
    "\n",
    "    def knn_classifier(self, features):\n",
    "        print('knn classifier')\n",
    "        train_features, train_labels = self.get_buffer_data()\n",
    "        test_features = features.to(self.device)\n",
    "        train_features = train_features.to(test_features.device)\n",
    "        train_labels = train_labels.to(test_features.device)\n",
    "    # Assuming train_features are transposed and ready to be used for dot product similarity\n",
    "        distances, indices = torch.cdist(test_features, train_features).topk(self.k, largest=False, sorted=True)\n",
    "        retrieved_neighbors = train_labels[indices]  # Retrieve labels of the k-nearest neighbors\n",
    "\n",
    "        # Voting or averaging can happen here depending on your approach, example with voting:\n",
    "        predictions, _ = torch.mode(retrieved_neighbors, dim=1)\n",
    "        print('prediction is', predictions)\n",
    "        print(self.mb_y)\n",
    "        return predictions\n",
    "    \n",
    "    def get_buffer_data(self):\n",
    "#         print(self.replay_plugin.ext_mem.values())\n",
    "#         print(self.replay_plugin.storage_policy.buffer_datasets)\n",
    "        \n",
    "        all_features = []\n",
    "        all_labels = []\n",
    "\n",
    "        # Iterate over each dataset in the buffer\n",
    "        for dataset in replay_plugin.storage_policy.buffer_datasets:\n",
    "#             print(dataset)\n",
    "            # Assuming the dataset provides a DataLoader to iterate over\n",
    "            loader = DataLoader(dataset, batch_size=self.train_mb_size, shuffle=False)\n",
    "            for data, target, _ in loader:\n",
    "                # Assuming data is already in the correct format or requires some preprocessing\n",
    "                # You may need to move data to the correct device if using GPU\n",
    "                data = data.to(self.device)\n",
    "                features = self.model(data)  # Extract features using the pre-trained model\n",
    "                all_features.append(features)\n",
    "                all_labels.append(target)\n",
    "\n",
    "        # Concatenate all features and labels from the buffer\n",
    "        train_features = torch.cat(all_features, dim=0)\n",
    "        train_labels = torch.cat(all_labels, dim=0)\n",
    "#         print(train_features.shape)\n",
    "        return train_features, train_labels\n",
    "    \n",
    "    def _after_eval_forward(self, **kwargs):\n",
    "        trigger_plugins(self, \"after_eval_forward\", **kwargs)\n",
    "        \n",
    "    def _after_eval_iteration(self, **kwargs):\n",
    "        trigger_plugins(self, \"after_eval_iteration\", **kwargs)\n",
    "#         strategy.loss = 0\n",
    "#         pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 910,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_53775/4023421110.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mreplay_plugin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKNN_storagePlugin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmem_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m60000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_policy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstorage_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mdino_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDINOFeatureExtractor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_53775/547384700.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, mem_size, batch_size, batch_size_mem, task_balanced_dataloader, storage_policy)\u001b[0m\n\u001b[1;32m     52\u001b[0m                 \u001b[0mmax_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmem_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madaptive_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             )\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy_metric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAccuracyMetric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'multiclass'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_53775/2488067052.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, task)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'multiclass'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;31m# Initialize the metric for multiclass classification by default\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'macro'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/thesis3.7/lib/python3.7/site-packages/torchmetrics/classification/accuracy.py\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(cls, task, threshold, num_classes, num_labels, average, multidim_average, top_k, ignore_index, validate_args, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mBinaryAccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtask\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop_k\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mMulticlassAccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_k\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from avalanche.training.plugins import ReplayPlugin\n",
    "\n",
    "\n",
    "replay_plugin = KNN_storagePlugin(mem_size=60000, storage_policy = storage_p)\n",
    "dino_model = DINOFeatureExtractor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 894,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model: Module,\n",
    "# #         optimizer: Optimizer,\n",
    "# #         criterion=CrossEntropyLoss(),\n",
    "#         train_mb_size: int = 1,\n",
    "#         train_epochs: int = 1,\n",
    "#         eval_mb_size: Optional[int] = 1,\n",
    "#         device=\"cpu\",\n",
    "#         plugins: Optional[List[\"SupervisedPlugin\"]] = None,\n",
    "#         evaluator: EvaluationPlugin = default_evaluator(),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 895,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/homes/55/enbo/miniconda3/envs/thesis3.7/lib/python3.7/site-packages/avalanche/training/templates/base.py:219: UserWarning: Plugin <__main__.KNN_storagePlugin object at 0x7f4ce2856590> implements incompatible callbacks for template <__main__.KNN_DINO1 object at 0x7f4c588c8c10>. This may result in errors. Incompatible callbacks: {'before_train_dataset_adaptation', 'after_eval_dataset_adaptation', 'after_train_dataset_adaptation', 'before_eval_dataset_adaptation'}\n",
      "  f\"Plugin {p} implements incompatible callbacks for template\"\n"
     ]
    }
   ],
   "source": [
    "cl_strategy = KNN_DINO1(\n",
    "    model=dino_model,\n",
    "    train_mb_size=32,\n",
    "    train_epochs=1,\n",
    "    eval_mb_size=16,\n",
    "    device=device,\n",
    "    evaluator=eval_plugin,\n",
    "    plugins=[replay_plugin]  # Use the KNN plugin\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 896,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cl_strategy = Naive(\n",
    "#     resnet_model, torch.optim.SGD(resnet_model.fc.parameters(), lr=0.01, momentum = 0.9),\n",
    "#     CrossEntropyLoss(), train_mb_size=32, train_epochs=1, eval_mb_size=16,\n",
    "#     # eval_every=500,\n",
    "#     device=device,\n",
    "#     evaluator=eval_plugin,\n",
    "#     plugins=[CustomReplay_SD(mem_size=60000, storage_policy = storage_p, \n",
    "#                              image_folder= 'saved_data/sd_turbo_i2i_50all_step20')]\n",
    "#     )\n",
    "# knn_classifier = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "from avalanche.training.storage_policy import ParametricBuffer, RandomExemplarsSelectionStrategy\n",
    "storage_p = ParametricBuffer(\n",
    "    max_size=60000,\n",
    "    groupby='class',\n",
    "    selection_strategy=RandomExemplarsSelectionStrategy()\n",
    "    # selection_strategy=RandomExemplarsSelectionStrategy()\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 897,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting experiment...\n",
      "Start of experience:  0\n",
      "Current Classes:  [0, 36, 5, 20, 54]\n",
      "2500\n",
      "<avalanche.benchmarks.utils.data_loader.TaskBalancedDataLoader object at 0x7f4d0c442a10>\n",
      "buffer size: 0\n",
      "_before_training_epoch\n",
      "training_epoch\n",
      "<avalanche.benchmarks.utils.data_loader.TaskBalancedDataLoader object at 0x7f4d0c442a10>\n",
      "_after_training_epoch\n",
      "after training exp buffer size: 2500\n",
      "Training completed\n",
      "Computing accuracy on the whole test set\n",
      "eval_dataset_adaptation\n",
      "500\n",
      "eval Model Adaptation \n",
      "knn classifier\n",
      "prediction is tensor([ 0, 20, 54, 20,  0,  5, 20, 36, 54,  0, 54, 36, 36, 36,  5,  0],\n",
      "       device='cuda:2')\n",
      "tensor([ 0, 20, 54, 20,  0, 20, 20, 36, 54,  0,  0, 36, 36, 36,  5,  0],\n",
      "       device='cuda:2')\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'Accuracy' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_53775/144813457.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Computing accuracy on the whole test set'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# test also returns a dictionary which contains all the metric values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcl_strategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbenchmark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_stream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/thesis3.7/lib/python3.7/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_53775/4175038894.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, exp_list, **kwargs)\u001b[0m\n\u001b[1;32m    334\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperience\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexp_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_before_eval_exp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_eval_exp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    337\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_after_eval_exp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_53775/4175038894.py\u001b[0m in \u001b[0;36m_eval_exp\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    414\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_eval_exp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0meval_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_53775/4175038894.py\u001b[0m in \u001b[0;36meval_epoch\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[0;31m#             self.loss = self.criterion()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_after_eval_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_before_eval_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m         \u001b[0mtrigger_plugins\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"before_eval_iteration\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_53775/4175038894.py\u001b[0m in \u001b[0;36m_after_eval_iteration\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_after_eval_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 494\u001b[0;31m         \u001b[0mtrigger_plugins\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"after_eval_iteration\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    495\u001b[0m \u001b[0;31m#         strategy.loss = 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m \u001b[0;31m#         pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/thesis3.7/lib/python3.7/site-packages/avalanche/training/utils.py\u001b[0m in \u001b[0;36mtrigger_plugins\u001b[0;34m(strategy, event, **kwargs)\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplugins\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m             \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_53775/1120495855.py\u001b[0m in \u001b[0;36mafter_eval_iteration\u001b[0;34m(self, strategy, **kwargs)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;31m# Update the accuracy metric\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy_metric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;31m# Log the current accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_53775/1035245711.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, preds, targets)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'Accuracy' object is not callable"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "print('Starting experiment...')\n",
    "results = []\n",
    "for experience in benchmark.train_stream:\n",
    "    print(\"Start of experience: \", experience.current_experience)\n",
    "    print(\"Current Classes: \", experience.classes_in_this_experience)\n",
    "\n",
    "    # train returns a dictionary which contains all the metric values\n",
    "    res = cl_strategy.train(experience)\n",
    "    print('Training completed')\n",
    "\n",
    "    print('Computing accuracy on the whole test set')\n",
    "    # test also returns a dictionary which contains all the metric values\n",
    "    results.append(cl_strategy.eval(benchmark.test_stream))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ClassificationDataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_53775/628550911.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhelp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mClassificationDataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'ClassificationDataset' is not defined"
     ]
    }
   ],
   "source": [
    "help(ClassificationDataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "increase batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark = SplitMNIST(n_experiences=5, seed=1)\n",
    "model = SimpleMLP(num_classes=10)\n",
    "optimizer = SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "criterion = CrossEntropyLoss()\n",
    "strategy = Naive(model=model, optimizer=optimizer, criterion=criterion, train_mb_size=128,\n",
    "                 )\n",
    "strategy.train(benchmark.train_stream)\n",
    "strategy.eval(benchmark.test_stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class KNN_DINO(BaseTemplate):\n",
    "#     \"\"\"Base class for continual learning with a KNN-DINO strategy.\"\"\"\n",
    "\n",
    "#     def __init__(\n",
    "#         self,\n",
    "#         model: Module,\n",
    "#         train_mb_size: int = 1,\n",
    "#         train_epochs: int = 1,\n",
    "#         eval_mb_size: Optional[int] = 1,\n",
    "#         device: str = \"cpu\",\n",
    "#         plugins: Optional[List] = None,\n",
    "#         evaluator: Optional[EvaluationPlugin] = None,\n",
    "#         eval_every: int = -1,\n",
    "#         peval_mode: str = \"epoch\",\n",
    "#         k: int = 5,\n",
    "#         T: float = 0.07\n",
    "#     ):\n",
    "#         super().__init__(model=model, device=device, plugins=plugins)\n",
    "#         self.model.to(self.device)\n",
    "        \n",
    "#         self.train_epochs = train_epochs\n",
    "#         self.train_mb_size = train_mb_size\n",
    "#         self.eval_mb_size = eval_mb_size if eval_mb_size is not None else train_mb_size\n",
    "#         self.evaluator = evaluator if evaluator is not None else EvaluationPlugin()\n",
    "#         self.plugins.append(self.evaluator)\n",
    "#         self.clock = Clock()\n",
    "#         self.plugins.append(self.clock)\n",
    "#         self.k = k\n",
    "#         self.T = T\n",
    "#         self.train_features = None\n",
    "#         self.train_labels = None\n",
    "\n",
    "#     @torch.no_grad()\n",
    "#     def train(self, experiences, **kwargs):\n",
    "#         self.model.eval()  # Set model to evaluation mode for feature extraction\n",
    "#         if not isinstance(experiences, Iterable):\n",
    "#             experiences = [experiences]\n",
    "#         for experience in experiences:\n",
    "#             self.prepare_features(experience)\n",
    "#             self._train_exp(experience, **kwargs)\n",
    "    \n",
    "#     def set_training_data(self, features, labels):\n",
    "#         \"\"\"Sets the training data for KNN.\"\"\"\n",
    "#         self.train_features = features.to(self.device)\n",
    "#         self.train_labels = labels.to(self.device)\n",
    "    \n",
    "\n",
    "#     def _train_exp(self, experience, **kwargs):\n",
    "#         self.experience = experience\n",
    "#         self.make_train_dataloader()  # Ensure data is ready for training\n",
    "#         for _ in range(self.train_epochs):\n",
    "#             self.training_epoch(**kwargs)\n",
    "\n",
    "#     def training_epoch(self, **kwargs):\n",
    "#         for self.mbatch in self.dataloader:\n",
    "#             self.mbatch = [x.to(self.device) for x in self.mbatch]\n",
    "#             self._unpack_minibatch()\n",
    "#             features = self.model(self.mbatch[0].to(self.device))\n",
    "#             if self.is_training:\n",
    "#                 # Store features for training the classifier\n",
    "#                 if self.train_features is None:\n",
    "#                     self.train_features = features\n",
    "#                     self.train_labels = self.mbatch[1]\n",
    "#                 else:\n",
    "#                     self.train_features = torch.cat((self.train_features, features), dim=0)\n",
    "#                     self.train_labels = torch.cat((self.train_labels, self.mbatch[1]), dim=0)\n",
    "#             else:\n",
    "#                 # Use features to classify using KNN\n",
    "#                 self.mb_output = self.knn_classifier(features)\n",
    "#             self._after_training_iteration(**kwargs)\n",
    "    \n",
    "#     def prepare_features(self, experience):\n",
    "#         \"\"\"Prepare features for the KNN classifier.\"\"\"\n",
    "#         # Here you would extract features using your model and set self.train_features and self.train_labels\n",
    "#         # This is just a placeholder, you need to implement the actual feature extraction\n",
    "#         loader = DataLoader(experience.dataset, batch_size=self.train_mb_size, shuffle=False)\n",
    "#         features, labels = [], []\n",
    "#         for batch in loader:\n",
    "#             if isinstance(batch, tuple) and len(batch) == 2:\n",
    "#                 data, target = batch\n",
    "#             else:\n",
    "#                 raise ValueError(\"Dataset must return tuples of (data, target)\")\n",
    "\n",
    "#             data = data.to(self.device)\n",
    "#             feature = self.model(data)\n",
    "#             features.append(feature.detach())  # Detach features to avoid saving gradients\n",
    "#             labels.append(target)\n",
    "\n",
    "#         self.train_features = torch.cat(features)\n",
    "#         self.train_labels = torch.cat(labels)\n",
    "#     def knn_classifier(self, test_features):\n",
    "#         if self.train_features is None or self.train_labels is None:\n",
    "#             raise ValueError(\"Training features and labels must be set before classification.\")\n",
    "#         distances, indices = torch.cdist(test_features, self.train_features).topk(self.k, largest=False, sorted=True)\n",
    "#         retrieved_neighbors = self.train_labels[indices]\n",
    "#         predictions, _ = torch.mode(retrieved_neighbors, dim=1)\n",
    "#         return predictions\n",
    "\n",
    "#     def make_train_dataloader(self):\n",
    "#         \"\"\"Create a DataLoader for the current experience.\"\"\"\n",
    "#         from torch.utils.data import DataLoader\n",
    "\n",
    "#         # Avalanche datasets can be directly used with DataLoader\n",
    "#         if hasattr(self.experience, 'dataset'):\n",
    "#             dataset = self.experience.dataset\n",
    "#         else:\n",
    "#             raise AttributeError(\"Experience object does not have 'dataset' attribute\")\n",
    "\n",
    "#         self.dataloader = DataLoader(dataset, batch_size=self.train_mb_size, shuffle=True, num_workers=0, pin_memory=True)\n",
    "\n",
    "#     def eval(self, exp_list, **kwargs):\n",
    "#         self.model.eval()\n",
    "#         for exp in exp_list:\n",
    "#             self._eval_exp(exp, **kwargs)\n",
    "\n",
    "#     def _eval_exp(self, experience, **kwargs):\n",
    "#         self.experience = experience\n",
    "#         self.make_train_dataloader()\n",
    "#         self.eval_epoch(**kwargs)\n",
    "\n",
    "#     def eval_epoch(self, **kwargs):\n",
    "#         for self.mbatch in self.dataloader:\n",
    "#             self.mbatch = [x.to(self.device) for x in self.mbatch]\n",
    "#             self._unpack_minibatch()\n",
    "#             features = self.model(self.mbatch[0].to(self.device))\n",
    "#             predictions = self.knn_classifier(features)\n",
    "#             self.mb_output = predictions  # Assign KNN predictions to minibatch output\n",
    "#             self._after_eval_iteration(**kwargs)\n",
    "\n",
    "#     def _unpack_minibatch(self):\n",
    "#         \"\"\"Prepare the minibatch for processing.\"\"\"\n",
    "#         if isinstance(self.mbatch, tuple):\n",
    "#             self.mbatch = (self.mbatch[0].to(self.device), self.mbatch[1].to(self.device))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import warnings\n",
    "# from collections import defaultdict\n",
    "# from typing import Iterable, Sequence, Optional, Union, List\n",
    "\n",
    "# import torch\n",
    "# from torch.nn import Module\n",
    "\n",
    "# from avalanche.benchmarks import CLExperience, CLStream\n",
    "# from avalanche.core import BasePlugin\n",
    "# from avalanche.training.utils import trigger_plugins\n",
    "\n",
    "# ExpSequence = Iterable[CLExperience]\n",
    "\n",
    "\n",
    "# class BaseTemplate:\n",
    "#     \"\"\"Base class for continual learning skeletons.\n",
    "\n",
    "#     **Training loop**\n",
    "#     The training loop is organized as follows::\n",
    "\n",
    "#         train\n",
    "#             train_exp  # for each experience\n",
    "\n",
    "#     **Evaluation loop**\n",
    "#     The evaluation loop is organized as follows::\n",
    "\n",
    "#         eval\n",
    "#             eval_exp  # for each experience\n",
    "\n",
    "#     \"\"\"\n",
    "\n",
    "#     # we need this only for type checking\n",
    "#     PLUGIN_CLASS = BasePlugin\n",
    "\n",
    "#     def __init__(\n",
    "#         self,\n",
    "#         model: Module,\n",
    "#         device=\"cpu\",\n",
    "#         plugins: Optional[List[BasePlugin]] = None,\n",
    "#     ):\n",
    "#         \"\"\"Init.\"\"\"\n",
    "\n",
    "#         self.model: Module = model\n",
    "#         \"\"\" PyTorch model. \"\"\"\n",
    "\n",
    "#         if device is None:\n",
    "#             device = 'cpu'\n",
    "\n",
    "#         self.device = torch.device(device)\n",
    "#         \"\"\" PyTorch device where the model will be allocated. \"\"\"\n",
    "\n",
    "#         self.plugins = [] if plugins is None else plugins\n",
    "#         \"\"\" List of `SupervisedPlugin`s. \"\"\"\n",
    "\n",
    "#         # check plugin compatibility\n",
    "#         self._check_plugin_compatibility()\n",
    "\n",
    "#         ###################################################################\n",
    "#         # State variables. These are updated during the train/eval loops. #\n",
    "#         ###################################################################\n",
    "#         self.experience: Optional[CLExperience] = None\n",
    "#         \"\"\" Current experience. \"\"\"\n",
    "\n",
    "#         self.is_training: bool = False\n",
    "#         \"\"\" True if the strategy is in training mode. \"\"\"\n",
    "\n",
    "#         self.current_eval_stream: Optional[ExpSequence] = None\n",
    "#         \"\"\" Current evaluation stream. \"\"\"\n",
    "\n",
    "#     @property\n",
    "#     def is_eval(self):\n",
    "#         \"\"\"True if the strategy is in evaluation mode.\"\"\"\n",
    "#         return not self.is_training\n",
    "\n",
    "#     def train(\n",
    "#         self,\n",
    "#         experiences: Union[CLExperience, ExpSequence],\n",
    "#         eval_streams: Optional[\n",
    "#             Sequence[Union[CLExperience, ExpSequence]]\n",
    "#         ] = None,\n",
    "#         **kwargs,\n",
    "#     ):\n",
    "#         \"\"\"Training loop.\n",
    "\n",
    "#         If experiences is a single element trains on it.\n",
    "#         If it is a sequence, trains the model on each experience in order.\n",
    "#         This is different from joint training on the entire stream.\n",
    "#         It returns a dictionary with last recorded value for each metric.\n",
    "\n",
    "#         :param experiences: single Experience or sequence.\n",
    "#         :param eval_streams: sequence of streams for evaluation.\n",
    "#             If None: use training experiences for evaluation.\n",
    "#             Use [] if you do not want to evaluate during training.\n",
    "#             Experiences in `eval_streams` are grouped by stream name\n",
    "#             when calling `eval`. If you use multiple streams, they must\n",
    "#             have different names.\n",
    "#         \"\"\"\n",
    "#         self.is_training = True\n",
    "#         self._stop_training = False\n",
    "\n",
    "#         self.model.train()\n",
    "#         self.model.to(self.device)\n",
    "\n",
    "#         # Normalize training and eval data.\n",
    "#         if not isinstance(experiences, Iterable):\n",
    "#             experiences = [experiences]\n",
    "#         if eval_streams is None:\n",
    "#             eval_streams = [experiences]\n",
    "\n",
    "#         self._eval_streams = _group_experiences_by_stream(eval_streams)\n",
    "\n",
    "#         self._before_training(**kwargs)\n",
    "\n",
    "#         for self.experience in experiences:\n",
    "#             self._before_training_exp(**kwargs)\n",
    "#             self._train_exp(self.experience, eval_streams, **kwargs)\n",
    "#             self._after_training_exp(**kwargs)\n",
    "#         self._after_training(**kwargs)\n",
    "\n",
    "#     def _train_exp(self, experience: CLExperience, eval_streams, **kwargs):\n",
    "#         raise NotImplementedError()\n",
    "\n",
    "#     @torch.no_grad()\n",
    "#     def eval(\n",
    "#         self,\n",
    "#         exp_list: Union[CLExperience, CLStream],\n",
    "#         **kwargs,\n",
    "#     ):\n",
    "#         \"\"\"\n",
    "#         Evaluate the current model on a series of experiences and\n",
    "#         returns the last recorded value for each metric.\n",
    "\n",
    "#         :param exp_list: CL experience information.\n",
    "#         :param kwargs: custom arguments.\n",
    "\n",
    "#         :return: dictionary containing last recorded value for\n",
    "#             each metric name\n",
    "#         \"\"\"\n",
    "#         # eval can be called inside the train method.\n",
    "#         # Save the shared state here to restore before returning.\n",
    "#         prev_train_state = self._save_train_state()\n",
    "#         self.is_training = False\n",
    "#         self.model.eval()\n",
    "\n",
    "#         if not isinstance(exp_list, Iterable):\n",
    "#             exp_list = [exp_list]\n",
    "#         self.current_eval_stream = exp_list\n",
    "\n",
    "#         self._before_eval(**kwargs)\n",
    "#         for self.experience in exp_list:\n",
    "#             self._before_eval_exp(**kwargs)\n",
    "#             self._eval_exp(**kwargs)\n",
    "#             self._after_eval_exp(**kwargs)\n",
    "\n",
    "#         self._after_eval(**kwargs)\n",
    "\n",
    "#         # restore previous shared state.\n",
    "#         self._load_train_state(prev_train_state)\n",
    "\n",
    "#     def _eval_exp(self, **kwargs):\n",
    "#         raise NotImplementedError()\n",
    "\n",
    "#     def _save_train_state(self):\n",
    "#         \"\"\"Save the training state, which may be modified by the eval loop.\n",
    "\n",
    "#         TODO: we probably need a better way to do this.\n",
    "#         \"\"\"\n",
    "#         # save each layer's training mode, to restore it later\n",
    "#         _prev_model_training_modes = {}\n",
    "#         for name, layer in self.model.named_modules():\n",
    "#             _prev_model_training_modes[name] = layer.training\n",
    "\n",
    "#         _prev_state = {\n",
    "#             \"experience\": self.experience,\n",
    "#             \"is_training\": self.is_training,\n",
    "#             \"model_training_mode\": _prev_model_training_modes,\n",
    "#         }\n",
    "#         return _prev_state\n",
    "\n",
    "#     def _load_train_state(self, prev_state):\n",
    "#         # restore train-state variables and training mode.\n",
    "#         self.experience = prev_state[\"experience\"]\n",
    "#         self.is_training = prev_state[\"is_training\"]\n",
    "\n",
    "#         # restore each layer's training mode to original\n",
    "#         prev_training_modes = prev_state[\"model_training_mode\"]\n",
    "#         for name, layer in self.model.named_modules():\n",
    "#             try:\n",
    "#                 prev_mode = prev_training_modes[name]\n",
    "#                 layer.train(mode=prev_mode)\n",
    "#             except KeyError:\n",
    "#                 # Unknown parameter, probably added during the eval\n",
    "#                 # model's adaptation. We set it to train mode.\n",
    "#                 layer.train()\n",
    "\n",
    "#     def _check_plugin_compatibility(self):\n",
    "#         \"\"\"Check that the list of plugins is compatible with the template.\n",
    "\n",
    "#         This means checking that each plugin impements a subset of the\n",
    "#         supported callbacks.\n",
    "#         \"\"\"\n",
    "#         # TODO: ideally we would like to check the argument's type to check\n",
    "#         #  that it's a supertype of the template.\n",
    "#         # I don't know if it's possible to do it in Python.\n",
    "#         ps = self.plugins\n",
    "\n",
    "#         def get_plugins_from_object(obj):\n",
    "#             def is_callback(x):\n",
    "#                 return x.startswith(\"before\") or x.startswith(\"after\")\n",
    "\n",
    "#             return filter(is_callback, dir(obj))\n",
    "\n",
    "#         cb_supported = set(get_plugins_from_object(self.PLUGIN_CLASS))\n",
    "#         for p in ps:\n",
    "#             cb_p = set(get_plugins_from_object(p))\n",
    "\n",
    "#             if not cb_p.issubset(cb_supported):\n",
    "#                 warnings.warn(\n",
    "#                     f\"Plugin {p} implements incompatible callbacks for template\"\n",
    "#                     f\" {self}. This may result in errors. Incompatible \"\n",
    "#                     f\"callbacks: {cb_p - cb_supported}\",\n",
    "#                 )\n",
    "#                 return\n",
    "\n",
    "#     #########################################################\n",
    "#     # Plugin Triggers                                       #\n",
    "#     #########################################################\n",
    "\n",
    "#     def _before_training_exp(self, **kwargs):\n",
    "#         trigger_plugins(self, \"before_training_exp\", **kwargs)\n",
    "\n",
    "#     def _after_training_exp(self, **kwargs):\n",
    "#         trigger_plugins(self, \"after_training_exp\", **kwargs)\n",
    "\n",
    "#     def _before_training(self, **kwargs):\n",
    "#         trigger_plugins(self, \"before_training\", **kwargs)\n",
    "\n",
    "#     def _after_training(self, **kwargs):\n",
    "#         trigger_plugins(self, \"after_training\", **kwargs)\n",
    "\n",
    "#     def _before_eval(self, **kwargs):\n",
    "#         trigger_plugins(self, \"before_eval\", **kwargs)\n",
    "\n",
    "#     def _after_eval(self, **kwargs):\n",
    "#         trigger_plugins(self, \"after_eval\", **kwargs)\n",
    "\n",
    "#     def _before_eval_exp(self, **kwargs):\n",
    "#         trigger_plugins(self, \"before_eval_exp\", **kwargs)\n",
    "\n",
    "#     def _after_eval_exp(self, **kwargs):\n",
    "#         trigger_plugins(self, \"after_eval_exp\", **kwargs)\n",
    "\n",
    "\n",
    "# def _group_experiences_by_stream(eval_streams):\n",
    "#     if len(eval_streams) == 1:\n",
    "#         return eval_streams\n",
    "\n",
    "#     exps = []\n",
    "#     # First, we unpack the list of experiences.\n",
    "#     for exp in eval_streams:\n",
    "#         if isinstance(exp, Iterable):\n",
    "#             exps.extend(exp)\n",
    "#         else:\n",
    "#             exps.append(exp)\n",
    "#     # Then, we group them by stream.\n",
    "#     exps_by_stream = defaultdict(list)\n",
    "#     for exp in exps:\n",
    "#         sname = exp.origin_stream.name\n",
    "#         exps_by_stream[sname].append(exp)\n",
    "#     # Finally, we return a list of lists.\n",
    "#     return list(exps_by_stream.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from avalanche.training.templates import BaseTemplate\n",
    "from avalanche.benchmarks import CLExperience\n",
    "from typing import Union, Optional, Sequence, List\n",
    "from torch.nn import Module\n",
    "from avalanche.training.plugins import EvaluationPlugin\n",
    "from avalanche.training.plugins.clock import Clock\n",
    "from avalanche.training.utils import trigger_plugins\n",
    "\n",
    "class KNN_DINO2(BaseTemplate):\n",
    "    \"\"\"Base class for continual learning with a KNN-DINO strategy.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        model: Module,\n",
    "        train_mb_size: int = 1,\n",
    "        train_epochs: int = 1,\n",
    "        eval_mb_size: Optional[int] = 1,\n",
    "        device: str = \"cpu\",\n",
    "        plugins: Optional[List] = None,\n",
    "        evaluator: Optional[EvaluationPlugin] = None,\n",
    "        eval_every: int = -1,\n",
    "        peval_mode: str = \"epoch\",\n",
    "        k: int = 5,\n",
    "        T: float = 0.07\n",
    "    ):\n",
    "        super().__init__(model=model, device=device, plugins=plugins)\n",
    "        self.train_epochs = train_epochs\n",
    "        self.train_mb_size = train_mb_size\n",
    "        self.eval_mb_size = eval_mb_size if eval_mb_size is not None else train_mb_size\n",
    "        self.evaluator = evaluator if evaluator is not None else EvaluationPlugin()\n",
    "        self.plugins.append(self.evaluator)\n",
    "        self.clock = Clock()\n",
    "        self.plugins.append(self.clock)\n",
    "        self.k = k\n",
    "        self.T = T\n",
    "        self.train_features = None\n",
    "        self.train_labels = None\n",
    "\n",
    "    def train(self, experiences, **kwargs):\n",
    "        if not isinstance(experiences, Iterable):\n",
    "            experiences = [experiences]\n",
    "#         if eval_streams is None:\n",
    "#             eval_streams = [experiences]\n",
    "\n",
    "        self.model.eval()  # Set model to evaluation mode for feature extraction\n",
    "        for experience in experiences:\n",
    "            self._train_exp(experience, **kwargs)\n",
    "\n",
    "    def _train_exp(self, experience, **kwargs):\n",
    "        self.experience = experience\n",
    "        self.make_train_dataloader()  # Ensure data is ready for training\n",
    "        for _ in range(self.train_epochs):\n",
    "            self.training_epoch(**kwargs)\n",
    "\n",
    "    def training_epoch(self, **kwargs):\n",
    "        print(self.dataloader)\n",
    "        for self.mbatch in self.dataloader:\n",
    "            self._unpack_minibatch()\n",
    "            features = self.model(self.mbatch[0].to(self.device))\n",
    "            if self.is_training:\n",
    "                # Store features for training the classifier\n",
    "                if self.train_features is None:\n",
    "                    self.train_features = features\n",
    "                    self.train_labels = self.mbatch[1]\n",
    "                else:\n",
    "                    self.train_features = torch.cat((self.train_features, features), dim=0)\n",
    "                    self.train_labels = torch.cat((self.train_labels, self.mbatch[1]), dim=0)\n",
    "            else:\n",
    "                # Use features to classify using KNN\n",
    "                self.mb_output = self.knn_classifier(features)\n",
    "            self._after_training_iteration(**kwargs)\n",
    "\n",
    "    def knn_classifier(self, test_features):\n",
    "        distances, indices = torch.cdist(test_features, self.train_features).topk(self.k, largest=False, sorted=True)\n",
    "        retrieved_neighbors = self.train_labels[indices]\n",
    "        predictions, _ = torch.mode(retrieved_neighbors, dim=1)\n",
    "        return predictions\n",
    "\n",
    "    def make_train_dataloader(self):\n",
    "#     \"\"\"Create a DataLoader for the current experience.\"\"\"\n",
    "        from torch.utils.data import DataLoader\n",
    "\n",
    "        # Avalanche datasets can be directly used with DataLoader\n",
    "        if hasattr(self.experience, 'dataset'):\n",
    "            dataset = self.experience.dataset\n",
    "        else:\n",
    "            raise AttributeError(\"Experience object does not have 'dataset' attribute\")\n",
    "\n",
    "        self.dataloader = DataLoader(dataset, batch_size=self.train_mb_size, shuffle=True, num_workers=0, pin_memory=True)\n",
    "\n",
    "\n",
    "    def eval(self, exp_list, **kwargs):\n",
    "        self.model.eval()\n",
    "        for exp in exp_list:\n",
    "            self._eval_exp(exp, **kwargs)\n",
    "\n",
    "    def _eval_exp(self, experience, **kwargs):\n",
    "        self.experience = experience\n",
    "        self.make_train_dataloader()\n",
    "        self.eval_epoch(**kwargs)\n",
    "\n",
    "    def eval_epoch(self, **kwargs):\n",
    "        for self.mbatch in self.dataloader:\n",
    "            self._unpack_minibatch()\n",
    "            features = self.model(self.mbatch[0].to(self.device))\n",
    "            self.mb_output = self.knn_classifier(features)\n",
    "            self._after_eval_iteration(**kwargs)\n",
    "    def _unpack_minibatch(self):\n",
    "#       self._check_minibatch()\n",
    "\n",
    "        if isinstance(self.mbatch, tuple):\n",
    "            self.mbatch = list(self.mbatch)\n",
    "        for i in range(len(self.mbatch)):\n",
    "            self.mbatch[i] = self.mbatch[i].to(self.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "ruhDj4_LBy1o"
   ],
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
